/*
  Licensed under the Apache License, Version 2.0
    http://www.apache.org/licenses/LICENSE-2.0.html

  AUTOGENERATED BY H2O at 2016-12-26T14:42:39.697+01:00
  3.10.0.8
  
  Standalone prediction code with sample test data for DeepLearningModel named h2o_nn_16x16x6_ReLU_08

  How to download, compile and execute:
      mkdir tmpdir
      cd tmpdir
      curl http://127.0.0.1:54321/3/h2o-genmodel.jar > h2o-genmodel.jar
      curl http://127.0.0.1:54321/3/Models.java/h2o_nn_16x16x6_ReLU_08 > h2o_nn_16x16x6_ReLU_08.java
      javac -cp h2o-genmodel.jar -J-Xmx2g -J-XX:MaxPermSize=128m h2o_nn_16x16x6_ReLU_08.java

     (Note:  Try java argument -XX:+PrintCompilation to show runtime JIT compiler behavior.)
*/
import java.util.Map;
import hex.genmodel.GenModel;
import hex.genmodel.annotations.ModelPojo;

@ModelPojo(name="h2o_nn_16x16x6_ReLU_08", algorithm="deeplearning")
public class h2o_nn_16x16x6_ReLU_08 extends GenModel {
  public hex.ModelCategory getModelCategory() { return hex.ModelCategory.Multinomial; }
  public boolean isSupervised() { return true; }
  public int nfeatures() { return 13; }
  public int nclasses() { return 6; }
  // Thread-local storage for input neuron activation values.
  final double[] NUMS = new double[13];
  static class NORMMUL implements java.io.Serializable {
    public static final double[] VALUES = null;
}
  static class NORMSUB implements java.io.Serializable {
    public static final double[] VALUES = null;
}
  // Workspace for categorical offsets.
  public static final int[] CATOFFSETS = {0};
  // Number of neurons for each layer.
  public static final int[] NEURONS = {13,16,16,6};
    // Thread-local storage for neuron activation values.
    final double[][] ACTIVATION = new double[][] {
      /* Input */ h2o_nn_16x16x6_ReLU_08_Activation_0.VALUES,
      /* Rectifier */ h2o_nn_16x16x6_ReLU_08_Activation_1.VALUES,
      /* Rectifier */ h2o_nn_16x16x6_ReLU_08_Activation_2.VALUES,
      /* Softmax */ h2o_nn_16x16x6_ReLU_08_Activation_3.VALUES
    };
    // Neuron bias values.
    public static final double[][] BIAS = new double[][] {
      /* Input */ h2o_nn_16x16x6_ReLU_08_Bias_0.VALUES,
      /* Rectifier */ h2o_nn_16x16x6_ReLU_08_Bias_1.VALUES,
      /* Rectifier */ h2o_nn_16x16x6_ReLU_08_Bias_2.VALUES,
      /* Softmax */ h2o_nn_16x16x6_ReLU_08_Bias_3.VALUES
    };
    // Connecting weights between neurons.
    public static final float[][] WEIGHT = new float[][] {
      /* Input */ h2o_nn_16x16x6_ReLU_08_Weight_0.VALUES,
      /* Rectifier */ h2o_nn_16x16x6_ReLU_08_Weight_1.VALUES,
      /* Rectifier */ h2o_nn_16x16x6_ReLU_08_Weight_2.VALUES,
      /* Softmax */ h2o_nn_16x16x6_ReLU_08_Weight_3.VALUES
    };

  // Names of columns used by model.
  public static final String[] NAMES = NamesHolder_h2o_nn_16x16x6_ReLU_08.VALUES;
  // Number of output classes included in training data response column.
  public static final int NCLASSES = 6;

  // Column domains. The last array contains domain of response column.
  public static final String[][] DOMAINS = new String[][] {
    /* X5 */ null,
    /* X12 */ null,
    /* X15 */ null,
    /* X17 */ null,
    /* X18 */ null,
    /* X19 */ null,
    /* X20 */ null,
    /* X21 */ null,
    /* X23 */ null,
    /* X27 */ null,
    /* X28 */ null,
    /* X34 */ null,
    /* X35 */ null,
    /* Label */ h2o_nn_16x16x6_ReLU_08_ColInfo_13.VALUES
  };
  // Prior class distribution
  public static final double[] PRIOR_CLASS_DISTRIB = {0.24528301886792453,0.12264150943396226,0.12264150943396226,0.1320754716981132,0.24528301886792453,0.1320754716981132};
  // Class distribution used for model building
  public static final double[] MODEL_CLASS_DISTRIB = null;

  public h2o_nn_16x16x6_ReLU_08() { super(NAMES,DOMAINS); }
  public String getUUID() { return Long.toString(-336480111540048016L); }

  // Pass in data in a double[], pre-aligned to the Model's requirements.
  // Jam predictions into the preds[] array; preds[0] is reserved for the
  // main prediction (class for classifiers or value for regression),
  // and remaining columns hold a probability distribution for classifiers.
  public final double[] score0( double[] data, double[] preds ) {
    java.util.Arrays.fill(preds,0);
    java.util.Arrays.fill(NUMS,0);
    int i = 0, ncats = 0;
    final int n = data.length;
    for(; i<n; ++i) {
      NUMS[i] = Double.isNaN(data[i]) ? 0 : data[i];
    }
    java.util.Arrays.fill(ACTIVATION[0],0);
    for (i=0; i<NUMS.length; ++i) {
      ACTIVATION[0][CATOFFSETS[CATOFFSETS.length-1] + i] = Double.isNaN(NUMS[i]) ? 0 : NUMS[i];
    }
    for (i=1; i<ACTIVATION.length; ++i) {
      java.util.Arrays.fill(ACTIVATION[i],0);
      int cols = ACTIVATION[i-1].length;
      int rows = ACTIVATION[i].length;
      int extra=cols-cols%8;
      int multiple = (cols/8)*8-1;
      int idx = 0;
      float[] a = WEIGHT[i];
      double[] x = ACTIVATION[i-1];
      double[] y = BIAS[i];
      double[] res = ACTIVATION[i];
      for (int row=0; row<rows; ++row) {
        double psum0 = 0, psum1 = 0, psum2 = 0, psum3 = 0, psum4 = 0, psum5 = 0, psum6 = 0, psum7 = 0;
        for (int col = 0; col < multiple; col += 8) {
          int off = idx + col;
          psum0 += a[off    ] * x[col    ];
          psum1 += a[off + 1] * x[col + 1];
          psum2 += a[off + 2] * x[col + 2];
          psum3 += a[off + 3] * x[col + 3];
          psum4 += a[off + 4] * x[col + 4];
          psum5 += a[off + 5] * x[col + 5];
          psum6 += a[off + 6] * x[col + 6];
          psum7 += a[off + 7] * x[col + 7];
        }
        res[row] += psum0 + psum1 + psum2 + psum3;
        res[row] += psum4 + psum5 + psum6 + psum7;
        for (int col = extra; col < cols; col++)
          res[row] += a[idx + col] * x[col];
        res[row] += y[row];
        idx += cols;
      }
      if (i<ACTIVATION.length-1) {
        for (int r=0; r<ACTIVATION[i].length; ++r) {
          ACTIVATION[i][r] = Math.max(0, ACTIVATION[i][r]);
        }
      }
      if (i == ACTIVATION.length-1) {
        double max = ACTIVATION[i][0];
        for (int r=1; r<ACTIVATION[i].length; r++) {
          if (ACTIVATION[i][r]>max) max = ACTIVATION[i][r];
        }
        double scale = 0;
        for (int r=0; r<ACTIVATION[i].length; r++) {
          ACTIVATION[i][r] = Math.exp(ACTIVATION[i][r] - max);
          scale += ACTIVATION[i][r];
        }
        for (int r=0; r<ACTIVATION[i].length; r++) {
          if (Double.isNaN(ACTIVATION[i][r]))
            throw new RuntimeException("Numerical instability, predicted NaN.");
          ACTIVATION[i][r] /= scale;
          preds[r+1] = ACTIVATION[i][r];
        }
      }
    }
    preds[0] = hex.genmodel.GenModel.getPrediction(preds, PRIOR_CLASS_DISTRIB, data, 0.5);
    return preds;
  }
}
// Neuron activation values for Input layer
class h2o_nn_16x16x6_ReLU_08_Activation_0 implements java.io.Serializable {
  public static final double[] VALUES = new double[13];
  static {
    h2o_nn_16x16x6_ReLU_08_Activation_0_0.fill(VALUES);
  }
  static final class h2o_nn_16x16x6_ReLU_08_Activation_0_0 implements java.io.Serializable {
    static final void fill(double[] sa) {
      sa[0] = 0.0;
      sa[1] = 0.0;
      sa[2] = 0.0;
      sa[3] = 0.0;
      sa[4] = 0.0;
      sa[5] = 0.0;
      sa[6] = 0.0;
      sa[7] = 0.0;
      sa[8] = 0.0;
      sa[9] = 0.0;
      sa[10] = 0.0;
      sa[11] = 0.0;
      sa[12] = 0.0;
    }
  }
}
// Neuron activation values for Rectifier layer
class h2o_nn_16x16x6_ReLU_08_Activation_1 implements java.io.Serializable {
  public static final double[] VALUES = new double[16];
  static {
    h2o_nn_16x16x6_ReLU_08_Activation_1_0.fill(VALUES);
  }
  static final class h2o_nn_16x16x6_ReLU_08_Activation_1_0 implements java.io.Serializable {
    static final void fill(double[] sa) {
      sa[0] = 0.0;
      sa[1] = 0.0;
      sa[2] = 0.0;
      sa[3] = 0.0;
      sa[4] = 0.0;
      sa[5] = 0.0;
      sa[6] = 0.0;
      sa[7] = 0.0;
      sa[8] = 0.0;
      sa[9] = 0.0;
      sa[10] = 0.0;
      sa[11] = 0.0;
      sa[12] = 0.0;
      sa[13] = 0.0;
      sa[14] = 0.0;
      sa[15] = 0.0;
    }
  }
}
// Neuron activation values for Rectifier layer
class h2o_nn_16x16x6_ReLU_08_Activation_2 implements java.io.Serializable {
  public static final double[] VALUES = new double[16];
  static {
    h2o_nn_16x16x6_ReLU_08_Activation_2_0.fill(VALUES);
  }
  static final class h2o_nn_16x16x6_ReLU_08_Activation_2_0 implements java.io.Serializable {
    static final void fill(double[] sa) {
      sa[0] = 0.0;
      sa[1] = 0.0;
      sa[2] = 0.0;
      sa[3] = 0.0;
      sa[4] = 0.0;
      sa[5] = 0.0;
      sa[6] = 0.0;
      sa[7] = 0.0;
      sa[8] = 0.0;
      sa[9] = 0.0;
      sa[10] = 0.0;
      sa[11] = 0.0;
      sa[12] = 0.0;
      sa[13] = 0.0;
      sa[14] = 0.0;
      sa[15] = 0.0;
    }
  }
}
// Neuron activation values for Softmax layer
class h2o_nn_16x16x6_ReLU_08_Activation_3 implements java.io.Serializable {
  public static final double[] VALUES = new double[6];
  static {
    h2o_nn_16x16x6_ReLU_08_Activation_3_0.fill(VALUES);
  }
  static final class h2o_nn_16x16x6_ReLU_08_Activation_3_0 implements java.io.Serializable {
    static final void fill(double[] sa) {
      sa[0] = 0.0;
      sa[1] = 0.0;
      sa[2] = 0.0;
      sa[3] = 0.0;
      sa[4] = 0.0;
      sa[5] = 0.0;
    }
  }
}
// Neuron bias values for Input layer
class h2o_nn_16x16x6_ReLU_08_Bias_0 implements java.io.Serializable {
  public static final double[] VALUES = null;
}
// Neuron bias values for Rectifier layer
class h2o_nn_16x16x6_ReLU_08_Bias_1 implements java.io.Serializable {
  public static final double[] VALUES = new double[16];
  static {
    h2o_nn_16x16x6_ReLU_08_Bias_1_0.fill(VALUES);
  }
  static final class h2o_nn_16x16x6_ReLU_08_Bias_1_0 implements java.io.Serializable {
    static final void fill(double[] sa) {
      sa[0] = 0.5934643930657313;
      sa[1] = 0.8432278816978231;
      sa[2] = 0.35156142000695484;
      sa[3] = 0.48194233172982537;
      sa[4] = 0.4589163465933438;
      sa[5] = 0.7114393748189833;
      sa[6] = 0.4406410811408641;
      sa[7] = 0.6619066102063971;
      sa[8] = 0.6697928909650017;
      sa[9] = 0.6745425837434975;
      sa[10] = 0.4831536046945483;
      sa[11] = 0.592233277316987;
      sa[12] = 0.3150707032824422;
      sa[13] = 0.3414470127591297;
      sa[14] = 0.5771665161783717;
      sa[15] = 0.49957402437949133;
    }
  }
}
// Neuron bias values for Rectifier layer
class h2o_nn_16x16x6_ReLU_08_Bias_2 implements java.io.Serializable {
  public static final double[] VALUES = new double[16];
  static {
    h2o_nn_16x16x6_ReLU_08_Bias_2_0.fill(VALUES);
  }
  static final class h2o_nn_16x16x6_ReLU_08_Bias_2_0 implements java.io.Serializable {
    static final void fill(double[] sa) {
      sa[0] = 1.0725068917303504;
      sa[1] = 1.1169766961457395;
      sa[2] = 0.8908754390287985;
      sa[3] = 1.000057342230118;
      sa[4] = 0.9183389225825002;
      sa[5] = 0.9591454790432633;
      sa[6] = 0.9839529774163319;
      sa[7] = 0.9869295770875057;
      sa[8] = 0.9369460340544605;
      sa[9] = 1.0769834677414571;
      sa[10] = 0.8808519987213;
      sa[11] = 1.1474752698021944;
      sa[12] = 1.019233281364859;
      sa[13] = 1.100458066042815;
      sa[14] = 0.9376836767895544;
      sa[15] = 0.9755303781467143;
    }
  }
}
// Neuron bias values for Softmax layer
class h2o_nn_16x16x6_ReLU_08_Bias_3 implements java.io.Serializable {
  public static final double[] VALUES = new double[6];
  static {
    h2o_nn_16x16x6_ReLU_08_Bias_3_0.fill(VALUES);
  }
  static final class h2o_nn_16x16x6_ReLU_08_Bias_3_0 implements java.io.Serializable {
    static final void fill(double[] sa) {
      sa[0] = -0.08140227699738718;
      sa[1] = 0.03634725064460698;
      sa[2] = -0.0053345354423329815;
      sa[3] = -0.01542460886988961;
      sa[4] = 0.05471301255193356;
      sa[5] = -0.10682045301554544;
    }
  }
}
class h2o_nn_16x16x6_ReLU_08_Weight_0 implements java.io.Serializable {
  public static final float[] VALUES = null;
}
// Neuron weights connecting Input and Rectifier layer
class h2o_nn_16x16x6_ReLU_08_Weight_1 implements java.io.Serializable {
  public static final float[] VALUES = new float[208];
  static {
    h2o_nn_16x16x6_ReLU_08_Weight_1_0.fill(VALUES);
  }
  static final class h2o_nn_16x16x6_ReLU_08_Weight_1_0 implements java.io.Serializable {
    static final void fill(float[] sa) {
      sa[0] = 0.24154997f;
      sa[1] = 0.356676f;
      sa[2] = 0.20489131f;
      sa[3] = 0.13162959f;
      sa[4] = 0.011435781f;
      sa[5] = -0.2282195f;
      sa[6] = -0.35068306f;
      sa[7] = 0.41768327f;
      sa[8] = 0.28321376f;
      sa[9] = -0.20009597f;
      sa[10] = 0.08736576f;
      sa[11] = -0.2817962f;
      sa[12] = 0.35469288f;
      sa[13] = -0.24072993f;
      sa[14] = -0.7179367f;
      sa[15] = -0.0064534033f;
      sa[16] = -0.07474108f;
      sa[17] = -0.057290334f;
      sa[18] = -0.24793138f;
      sa[19] = 0.029854834f;
      sa[20] = 0.47431028f;
      sa[21] = -0.30532205f;
      sa[22] = 0.49124417f;
      sa[23] = -0.053176176f;
      sa[24] = 0.24410357f;
      sa[25] = 0.472944f;
      sa[26] = -0.49008495f;
      sa[27] = 0.4360748f;
      sa[28] = 0.30799016f;
      sa[29] = -0.3993969f;
      sa[30] = -0.3937101f;
      sa[31] = 0.1999732f;
      sa[32] = 0.5678027f;
      sa[33] = -0.5032783f;
      sa[34] = 0.07839025f;
      sa[35] = -0.18458185f;
      sa[36] = -0.04117143f;
      sa[37] = 0.40822706f;
      sa[38] = -0.35182884f;
      sa[39] = 0.27959087f;
      sa[40] = 0.06827107f;
      sa[41] = -0.19580454f;
      sa[42] = -0.4005153f;
      sa[43] = -0.20392542f;
      sa[44] = 0.48009494f;
      sa[45] = -0.5290144f;
      sa[46] = 0.011331313f;
      sa[47] = 0.05326882f;
      sa[48] = 0.33880615f;
      sa[49] = 0.3474546f;
      sa[50] = 0.390354f;
      sa[51] = -0.52576864f;
      sa[52] = -0.14148478f;
      sa[53] = 0.39067978f;
      sa[54] = 0.27143866f;
      sa[55] = -0.11995224f;
      sa[56] = -0.41569144f;
      sa[57] = -0.22466291f;
      sa[58] = 0.34169546f;
      sa[59] = -0.3050199f;
      sa[60] = -0.41897565f;
      sa[61] = 0.32132444f;
      sa[62] = -0.123915575f;
      sa[63] = 0.09371321f;
      sa[64] = 0.08102932f;
      sa[65] = 0.20263566f;
      sa[66] = 0.27115554f;
      sa[67] = 0.40084288f;
      sa[68] = 0.08063655f;
      sa[69] = 0.37724137f;
      sa[70] = -0.19752875f;
      sa[71] = 0.23214269f;
      sa[72] = -0.11073501f;
      sa[73] = 0.32328922f;
      sa[74] = -0.21510683f;
      sa[75] = -0.10444731f;
      sa[76] = -0.2514566f;
      sa[77] = -0.27595678f;
      sa[78] = -0.17073561f;
      sa[79] = 0.35298496f;
      sa[80] = -0.239562f;
      sa[81] = -0.08417997f;
      sa[82] = -0.14545754f;
      sa[83] = 0.23031923f;
      sa[84] = -0.09952395f;
      sa[85] = -0.25831467f;
      sa[86] = 0.19211145f;
      sa[87] = 0.4249752f;
      sa[88] = 0.032422256f;
      sa[89] = 0.09673415f;
      sa[90] = -0.26269016f;
      sa[91] = 0.2513446f;
      sa[92] = 0.32846183f;
      sa[93] = -0.34138757f;
      sa[94] = -0.45085332f;
      sa[95] = -0.47076416f;
      sa[96] = 0.36776403f;
      sa[97] = -0.28982487f;
      sa[98] = 0.3839164f;
      sa[99] = -0.09930049f;
      sa[100] = 0.014452851f;
      sa[101] = -0.55436486f;
      sa[102] = -0.5558896f;
      sa[103] = 0.02469501f;
      sa[104] = 0.08282744f;
      sa[105] = -0.6274707f;
      sa[106] = -0.18624793f;
      sa[107] = 0.14052726f;
      sa[108] = 0.29101148f;
      sa[109] = -0.27353123f;
      sa[110] = -0.46150145f;
      sa[111] = 0.3026749f;
      sa[112] = 0.28275856f;
      sa[113] = 0.18562642f;
      sa[114] = -0.14240637f;
      sa[115] = 0.11356057f;
      sa[116] = -0.43318155f;
      sa[117] = 0.08800725f;
      sa[118] = -0.54948187f;
      sa[119] = -0.3242442f;
      sa[120] = 0.0044814944f;
      sa[121] = 0.1727421f;
      sa[122] = 0.49780846f;
      sa[123] = 0.22979668f;
      sa[124] = 0.44040212f;
      sa[125] = 0.49266696f;
      sa[126] = -0.35873646f;
      sa[127] = -0.026588688f;
      sa[128] = 0.026321674f;
      sa[129] = 0.5064581f;
      sa[130] = -0.23060201f;
      sa[131] = 0.6602593f;
      sa[132] = 0.29304072f;
      sa[133] = -0.41837314f;
      sa[134] = 0.14074446f;
      sa[135] = -0.2819075f;
      sa[136] = -0.36878407f;
      sa[137] = -0.036019072f;
      sa[138] = 0.13662682f;
      sa[139] = -0.12215421f;
      sa[140] = -0.34445283f;
      sa[141] = -0.199644f;
      sa[142] = 0.14668578f;
      sa[143] = -0.39656273f;
      sa[144] = 0.5254035f;
      sa[145] = -0.15338194f;
      sa[146] = -0.16205975f;
      sa[147] = 0.44694376f;
      sa[148] = 0.11611609f;
      sa[149] = 0.5053849f;
      sa[150] = 0.45911312f;
      sa[151] = -0.369268f;
      sa[152] = -0.041392483f;
      sa[153] = 0.4981175f;
      sa[154] = 0.23255256f;
      sa[155] = -0.22114466f;
      sa[156] = 0.03180452f;
      sa[157] = -0.2333921f;
      sa[158] = 0.08684349f;
      sa[159] = 0.07731119f;
      sa[160] = -0.096413545f;
      sa[161] = 0.352821f;
      sa[162] = 0.053978637f;
      sa[163] = -0.20302671f;
      sa[164] = 0.26978812f;
      sa[165] = -0.07906594f;
      sa[166] = -0.48864627f;
      sa[167] = -0.25384158f;
      sa[168] = 0.28383029f;
      sa[169] = 0.4199273f;
      sa[170] = -0.28933728f;
      sa[171] = -0.19629766f;
      sa[172] = -0.22303656f;
      sa[173] = -0.34360278f;
      sa[174] = 0.005597637f;
      sa[175] = -0.13581274f;
      sa[176] = -0.12305036f;
      sa[177] = -0.07330593f;
      sa[178] = -0.04871123f;
      sa[179] = 0.44077444f;
      sa[180] = -0.024591923f;
      sa[181] = -0.32087788f;
      sa[182] = -0.09446391f;
      sa[183] = 0.4000615f;
      sa[184] = 0.5019904f;
      sa[185] = 0.30713326f;
      sa[186] = -0.18484539f;
      sa[187] = 0.12316294f;
      sa[188] = -0.34364215f;
      sa[189] = 0.38392463f;
      sa[190] = 0.09738905f;
      sa[191] = 0.015037549f;
      sa[192] = -0.28498375f;
      sa[193] = 0.45494196f;
      sa[194] = -0.026738582f;
      sa[195] = 0.4779982f;
      sa[196] = 0.39836967f;
      sa[197] = -0.18538912f;
      sa[198] = -0.06769975f;
      sa[199] = -0.1312945f;
      sa[200] = 0.13008995f;
      sa[201] = -0.63553333f;
      sa[202] = 0.19299315f;
      sa[203] = 0.00633833f;
      sa[204] = -0.19714561f;
      sa[205] = 0.504994f;
      sa[206] = 0.36228386f;
      sa[207] = 0.30633053f;
    }
  }
}
// Neuron weights connecting Rectifier and Rectifier layer
class h2o_nn_16x16x6_ReLU_08_Weight_2 implements java.io.Serializable {
  public static final float[] VALUES = new float[256];
  static {
    h2o_nn_16x16x6_ReLU_08_Weight_2_0.fill(VALUES);
  }
  static final class h2o_nn_16x16x6_ReLU_08_Weight_2_0 implements java.io.Serializable {
    static final void fill(float[] sa) {
      sa[0] = 0.50289214f;
      sa[1] = 0.0130496295f;
      sa[2] = -0.2971845f;
      sa[3] = -0.43141466f;
      sa[4] = 0.07959277f;
      sa[5] = 0.17969401f;
      sa[6] = 0.24302983f;
      sa[7] = -0.12038714f;
      sa[8] = -0.29033646f;
      sa[9] = 0.28208774f;
      sa[10] = 0.07625418f;
      sa[11] = 0.06974376f;
      sa[12] = 0.15474598f;
      sa[13] = -0.041553468f;
      sa[14] = -0.40019923f;
      sa[15] = 0.32690045f;
      sa[16] = 0.58623135f;
      sa[17] = -0.117326185f;
      sa[18] = 0.0069504506f;
      sa[19] = -0.0794737f;
      sa[20] = 0.38721326f;
      sa[21] = 0.12678835f;
      sa[22] = -0.20164187f;
      sa[23] = 0.33834186f;
      sa[24] = -0.25266382f;
      sa[25] = 0.1195253f;
      sa[26] = 0.13462184f;
      sa[27] = 0.48994917f;
      sa[28] = -0.33810452f;
      sa[29] = -0.10982564f;
      sa[30] = 0.22859566f;
      sa[31] = 0.0039221332f;
      sa[32] = -0.37192005f;
      sa[33] = -0.55225843f;
      sa[34] = 0.006559272f;
      sa[35] = 0.31664303f;
      sa[36] = -0.09288964f;
      sa[37] = -0.035100684f;
      sa[38] = -1.2429629E-4f;
      sa[39] = 0.14098704f;
      sa[40] = -0.29668373f;
      sa[41] = -0.4949833f;
      sa[42] = -0.28436637f;
      sa[43] = -0.3688938f;
      sa[44] = -0.07449569f;
      sa[45] = -0.4357576f;
      sa[46] = 0.27551836f;
      sa[47] = 0.30933216f;
      sa[48] = -0.33946827f;
      sa[49] = -0.29856488f;
      sa[50] = 0.13161121f;
      sa[51] = -0.21910971f;
      sa[52] = 0.27500772f;
      sa[53] = 0.28258878f;
      sa[54] = -0.114583895f;
      sa[55] = 0.37224978f;
      sa[56] = -0.23762502f;
      sa[57] = -0.30431014f;
      sa[58] = 0.057258718f;
      sa[59] = -0.18416497f;
      sa[60] = 0.3903907f;
      sa[61] = -0.21886134f;
      sa[62] = -0.050206717f;
      sa[63] = -0.024999157f;
      sa[64] = 0.3173185f;
      sa[65] = -0.21427885f;
      sa[66] = 0.22728f;
      sa[67] = 0.41187897f;
      sa[68] = 0.17939197f;
      sa[69] = -0.35229737f;
      sa[70] = -0.43202302f;
      sa[71] = -0.1508242f;
      sa[72] = -0.44227004f;
      sa[73] = 0.2952784f;
      sa[74] = 0.2820133f;
      sa[75] = -0.03195766f;
      sa[76] = 0.22143398f;
      sa[77] = 0.12245245f;
      sa[78] = -0.4097466f;
      sa[79] = 0.20324032f;
      sa[80] = -0.23488726f;
      sa[81] = 0.072056286f;
      sa[82] = 0.19199444f;
      sa[83] = -0.21891351f;
      sa[84] = -0.4513609f;
      sa[85] = -0.32375392f;
      sa[86] = 0.0046961326f;
      sa[87] = 0.24433626f;
      sa[88] = -0.4071111f;
      sa[89] = -0.14273196f;
      sa[90] = -0.3441014f;
      sa[91] = 0.399985f;
      sa[92] = -0.13077052f;
      sa[93] = 0.06310049f;
      sa[94] = -0.49680147f;
      sa[95] = -0.088054225f;
      sa[96] = -0.24010552f;
      sa[97] = -0.03336507f;
      sa[98] = -0.06805703f;
      sa[99] = -0.08407433f;
      sa[100] = -0.28504953f;
      sa[101] = -0.03346058f;
      sa[102] = 0.2736725f;
      sa[103] = -0.0027931673f;
      sa[104] = -0.09233739f;
      sa[105] = -0.16721416f;
      sa[106] = 0.44837543f;
      sa[107] = 0.2900437f;
      sa[108] = 0.19691059f;
      sa[109] = -0.08795644f;
      sa[110] = 0.13458686f;
      sa[111] = -0.35429847f;
      sa[112] = -0.38480282f;
      sa[113] = 0.07356233f;
      sa[114] = 0.09178019f;
      sa[115] = -0.14162956f;
      sa[116] = 0.39723405f;
      sa[117] = 0.11529301f;
      sa[118] = -0.38775828f;
      sa[119] = -0.24867281f;
      sa[120] = -0.034740604f;
      sa[121] = 0.31841615f;
      sa[122] = -0.21203294f;
      sa[123] = 0.056113407f;
      sa[124] = -0.24109392f;
      sa[125] = 0.21762118f;
      sa[126] = -0.3153346f;
      sa[127] = -0.10591295f;
      sa[128] = -0.4146968f;
      sa[129] = 0.16114515f;
      sa[130] = -0.0019103538f;
      sa[131] = 0.30785227f;
      sa[132] = 0.08698759f;
      sa[133] = 0.058785953f;
      sa[134] = 0.21690096f;
      sa[135] = -0.28113893f;
      sa[136] = 0.1918612f;
      sa[137] = -0.29897183f;
      sa[138] = -0.16499694f;
      sa[139] = 0.28209007f;
      sa[140] = -0.17299612f;
      sa[141] = 0.011790493f;
      sa[142] = 0.15332009f;
      sa[143] = -0.3947335f;
      sa[144] = 0.19633454f;
      sa[145] = -0.09665531f;
      sa[146] = 0.07007262f;
      sa[147] = 0.15090199f;
      sa[148] = -0.32839116f;
      sa[149] = 0.27116817f;
      sa[150] = -0.17826475f;
      sa[151] = -0.47137702f;
      sa[152] = 0.62583447f;
      sa[153] = -0.25161034f;
      sa[154] = 0.35736737f;
      sa[155] = -0.31350526f;
      sa[156] = -0.43089563f;
      sa[157] = -0.21396378f;
      sa[158] = 0.104474425f;
      sa[159] = 0.010938638f;
      sa[160] = 0.22370784f;
      sa[161] = -0.33221984f;
      sa[162] = 0.4842808f;
      sa[163] = -0.2981549f;
      sa[164] = 0.19979505f;
      sa[165] = -0.17382753f;
      sa[166] = 0.29521492f;
      sa[167] = -0.43530962f;
      sa[168] = 0.2277959f;
      sa[169] = -0.4357957f;
      sa[170] = 0.15634154f;
      sa[171] = 0.14010674f;
      sa[172] = 0.36192402f;
      sa[173] = 0.32179478f;
      sa[174] = -0.06449449f;
      sa[175] = -0.3836164f;
      sa[176] = -0.08439547f;
      sa[177] = 0.74577403f;
      sa[178] = -0.3925612f;
      sa[179] = -0.07251854f;
      sa[180] = -0.36239904f;
      sa[181] = -0.2773605f;
      sa[182] = 0.092370875f;
      sa[183] = 0.10705228f;
      sa[184] = 0.4383379f;
      sa[185] = 0.5605516f;
      sa[186] = -0.050216995f;
      sa[187] = -0.46631044f;
      sa[188] = 0.09713921f;
      sa[189] = -0.12890479f;
      sa[190] = -0.36750498f;
      sa[191] = -0.43670106f;
      sa[192] = -0.1051148f;
      sa[193] = 0.16548064f;
      sa[194] = -0.18316379f;
      sa[195] = 3.8415063E-4f;
      sa[196] = 0.12560652f;
      sa[197] = -0.28227997f;
      sa[198] = 0.12706089f;
      sa[199] = 0.4621754f;
      sa[200] = 0.020802291f;
      sa[201] = 0.23954664f;
      sa[202] = 0.14271495f;
      sa[203] = -0.37224266f;
      sa[204] = 0.14395574f;
      sa[205] = 0.48852924f;
      sa[206] = -0.043425836f;
      sa[207] = 0.26250112f;
      sa[208] = -0.09127854f;
      sa[209] = 0.2816692f;
      sa[210] = -0.11234113f;
      sa[211] = -0.36282954f;
      sa[212] = -0.2851389f;
      sa[213] = 0.21418443f;
      sa[214] = -0.37429193f;
      sa[215] = -0.11612433f;
      sa[216] = 0.14945869f;
      sa[217] = 0.49709114f;
      sa[218] = 0.014970705f;
      sa[219] = 0.15691641f;
      sa[220] = 0.14859203f;
      sa[221] = -0.024728814f;
      sa[222] = -0.38636002f;
      sa[223] = -0.3047976f;
      sa[224] = 0.29184037f;
      sa[225] = 0.079767235f;
      sa[226] = -0.14065905f;
      sa[227] = -0.053197503f;
      sa[228] = -0.17100716f;
      sa[229] = -0.19462344f;
      sa[230] = -0.36153463f;
      sa[231] = -0.33863077f;
      sa[232] = 0.31930485f;
      sa[233] = -0.11757594f;
      sa[234] = -0.24190854f;
      sa[235] = 0.06966653f;
      sa[236] = -0.44197372f;
      sa[237] = 0.37460116f;
      sa[238] = 0.013000226f;
      sa[239] = 0.0048940615f;
      sa[240] = -0.15793607f;
      sa[241] = -0.3940246f;
      sa[242] = -0.2103809f;
      sa[243] = 0.57000846f;
      sa[244] = 0.13091062f;
      sa[245] = 0.26978916f;
      sa[246] = 0.25609046f;
      sa[247] = -0.4713869f;
      sa[248] = -0.1685048f;
      sa[249] = -0.07650675f;
      sa[250] = 0.19850834f;
      sa[251] = 0.60675997f;
      sa[252] = 0.09844378f;
      sa[253] = -0.25980502f;
      sa[254] = 0.41462722f;
      sa[255] = 0.42561096f;
    }
  }
}
// Neuron weights connecting Rectifier and Softmax layer
class h2o_nn_16x16x6_ReLU_08_Weight_3 implements java.io.Serializable {
  public static final float[] VALUES = new float[96];
  static {
    h2o_nn_16x16x6_ReLU_08_Weight_3_0.fill(VALUES);
  }
  static final class h2o_nn_16x16x6_ReLU_08_Weight_3_0 implements java.io.Serializable {
    static final void fill(float[] sa) {
      sa[0] = -0.05181521f;
      sa[1] = -1.6384376f;
      sa[2] = -1.5835645f;
      sa[3] = 1.2574636f;
      sa[4] = 0.3217673f;
      sa[5] = -0.20606507f;
      sa[6] = -1.6503627f;
      sa[7] = 1.4332145f;
      sa[8] = 1.7650423f;
      sa[9] = 0.030245135f;
      sa[10] = 1.5796164f;
      sa[11] = 1.254259f;
      sa[12] = 1.7736305f;
      sa[13] = -0.7201103f;
      sa[14] = -1.9312608f;
      sa[15] = -0.7558186f;
      sa[16] = 0.7465161f;
      sa[17] = -0.72153467f;
      sa[18] = -1.4612914f;
      sa[19] = -0.898062f;
      sa[20] = -1.8805691f;
      sa[21] = 0.30745307f;
      sa[22] = -1.909438f;
      sa[23] = -0.6691732f;
      sa[24] = -0.49923018f;
      sa[25] = 1.9145336f;
      sa[26] = -0.32228658f;
      sa[27] = 1.2126805f;
      sa[28] = 1.222301f;
      sa[29] = -0.81381524f;
      sa[30] = 0.21388009f;
      sa[31] = 0.19294758f;
      sa[32] = 0.3426765f;
      sa[33] = 0.2890634f;
      sa[34] = -0.51558125f;
      sa[35] = 1.0025901f;
      sa[36] = 0.53123355f;
      sa[37] = -1.3169246f;
      sa[38] = 0.5987568f;
      sa[39] = -0.36299387f;
      sa[40] = 0.2806853f;
      sa[41] = -0.64646935f;
      sa[42] = 0.5711044f;
      sa[43] = -1.8098996f;
      sa[44] = 0.8942313f;
      sa[45] = -2.4097662f;
      sa[46] = -2.0661662f;
      sa[47] = 0.12211736f;
      sa[48] = 1.6568947f;
      sa[49] = -0.22715123f;
      sa[50] = -0.53612417f;
      sa[51] = 1.7880735f;
      sa[52] = -1.6851124f;
      sa[53] = 0.8895457f;
      sa[54] = 1.7250243f;
      sa[55] = 1.1158863f;
      sa[56] = -0.66849244f;
      sa[57] = -0.0090584215f;
      sa[58] = 1.019296f;
      sa[59] = 0.88273615f;
      sa[60] = -1.3809719f;
      sa[61] = 1.0243952f;
      sa[62] = -0.4268904f;
      sa[63] = -0.8844965f;
      sa[64] = 0.9786358f;
      sa[65] = -0.8593248f;
      sa[66] = -1.7463273f;
      sa[67] = -0.067367084f;
      sa[68] = 0.9365839f;
      sa[69] = -1.3348436f;
      sa[70] = -1.5825566f;
      sa[71] = -0.09632774f;
      sa[72] = -1.0764574f;
      sa[73] = -1.226172f;
      sa[74] = -1.1345999f;
      sa[75] = 1.5622182f;
      sa[76] = 1.937603f;
      sa[77] = -0.5227221f;
      sa[78] = -1.4233872f;
      sa[79] = -0.40563178f;
      sa[80] = 0.5884895f;
      sa[81] = -1.7335595f;
      sa[82] = -0.2461117f;
      sa[83] = -1.4682099f;
      sa[84] = 1.5335732f;
      sa[85] = 1.0898105f;
      sa[86] = -2.0078118f;
      sa[87] = 1.1455365f;
      sa[88] = -1.6172299f;
      sa[89] = -1.011773f;
      sa[90] = 0.21341011f;
      sa[91] = 0.059529644f;
      sa[92] = 1.2469f;
      sa[93] = 1.9078033f;
      sa[94] = 1.5245711f;
      sa[95] = 0.6171871f;
    }
  }
}
// The class representing training column names
class NamesHolder_h2o_nn_16x16x6_ReLU_08 implements java.io.Serializable {
  public static final String[] VALUES = new String[13];
  static {
    NamesHolder_h2o_nn_16x16x6_ReLU_08_0.fill(VALUES);
  }
  static final class NamesHolder_h2o_nn_16x16x6_ReLU_08_0 implements java.io.Serializable {
    static final void fill(String[] sa) {
      sa[0] = "X5";
      sa[1] = "X12";
      sa[2] = "X15";
      sa[3] = "X17";
      sa[4] = "X18";
      sa[5] = "X19";
      sa[6] = "X20";
      sa[7] = "X21";
      sa[8] = "X23";
      sa[9] = "X27";
      sa[10] = "X28";
      sa[11] = "X34";
      sa[12] = "X35";
    }
  }
}
// The class representing column Label
class h2o_nn_16x16x6_ReLU_08_ColInfo_13 implements java.io.Serializable {
  public static final String[] VALUES = new String[6];
  static {
    h2o_nn_16x16x6_ReLU_08_ColInfo_13_0.fill(VALUES);
  }
  static final class h2o_nn_16x16x6_ReLU_08_ColInfo_13_0 implements java.io.Serializable {
    static final void fill(String[] sa) {
      sa[0] = "1";
      sa[1] = "2";
      sa[2] = "3";
      sa[3] = "4";
      sa[4] = "5";
      sa[5] = "6";
    }
  }
}


