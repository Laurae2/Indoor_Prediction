/*
  Licensed under the Apache License, Version 2.0
    http://www.apache.org/licenses/LICENSE-2.0.html

  AUTOGENERATED BY H2O at 2016-12-26T14:41:43.954+01:00
  3.10.0.8
  
  Standalone prediction code with sample test data for DeepLearningModel named h2o_nn_16x16x6_ReLU_04

  How to download, compile and execute:
      mkdir tmpdir
      cd tmpdir
      curl http://127.0.0.1:54321/3/h2o-genmodel.jar > h2o-genmodel.jar
      curl http://127.0.0.1:54321/3/Models.java/h2o_nn_16x16x6_ReLU_04 > h2o_nn_16x16x6_ReLU_04.java
      javac -cp h2o-genmodel.jar -J-Xmx2g -J-XX:MaxPermSize=128m h2o_nn_16x16x6_ReLU_04.java

     (Note:  Try java argument -XX:+PrintCompilation to show runtime JIT compiler behavior.)
*/
import java.util.Map;
import hex.genmodel.GenModel;
import hex.genmodel.annotations.ModelPojo;

@ModelPojo(name="h2o_nn_16x16x6_ReLU_04", algorithm="deeplearning")
public class h2o_nn_16x16x6_ReLU_04 extends GenModel {
  public hex.ModelCategory getModelCategory() { return hex.ModelCategory.Multinomial; }
  public boolean isSupervised() { return true; }
  public int nfeatures() { return 13; }
  public int nclasses() { return 6; }
  // Thread-local storage for input neuron activation values.
  final double[] NUMS = new double[13];
  static class NORMMUL implements java.io.Serializable {
    public static final double[] VALUES = null;
}
  static class NORMSUB implements java.io.Serializable {
    public static final double[] VALUES = null;
}
  // Workspace for categorical offsets.
  public static final int[] CATOFFSETS = {0};
  // Number of neurons for each layer.
  public static final int[] NEURONS = {13,16,16,6};
    // Thread-local storage for neuron activation values.
    final double[][] ACTIVATION = new double[][] {
      /* Input */ h2o_nn_16x16x6_ReLU_04_Activation_0.VALUES,
      /* Rectifier */ h2o_nn_16x16x6_ReLU_04_Activation_1.VALUES,
      /* Rectifier */ h2o_nn_16x16x6_ReLU_04_Activation_2.VALUES,
      /* Softmax */ h2o_nn_16x16x6_ReLU_04_Activation_3.VALUES
    };
    // Neuron bias values.
    public static final double[][] BIAS = new double[][] {
      /* Input */ h2o_nn_16x16x6_ReLU_04_Bias_0.VALUES,
      /* Rectifier */ h2o_nn_16x16x6_ReLU_04_Bias_1.VALUES,
      /* Rectifier */ h2o_nn_16x16x6_ReLU_04_Bias_2.VALUES,
      /* Softmax */ h2o_nn_16x16x6_ReLU_04_Bias_3.VALUES
    };
    // Connecting weights between neurons.
    public static final float[][] WEIGHT = new float[][] {
      /* Input */ h2o_nn_16x16x6_ReLU_04_Weight_0.VALUES,
      /* Rectifier */ h2o_nn_16x16x6_ReLU_04_Weight_1.VALUES,
      /* Rectifier */ h2o_nn_16x16x6_ReLU_04_Weight_2.VALUES,
      /* Softmax */ h2o_nn_16x16x6_ReLU_04_Weight_3.VALUES
    };

  // Names of columns used by model.
  public static final String[] NAMES = NamesHolder_h2o_nn_16x16x6_ReLU_04.VALUES;
  // Number of output classes included in training data response column.
  public static final int NCLASSES = 6;

  // Column domains. The last array contains domain of response column.
  public static final String[][] DOMAINS = new String[][] {
    /* X5 */ null,
    /* X12 */ null,
    /* X15 */ null,
    /* X17 */ null,
    /* X18 */ null,
    /* X19 */ null,
    /* X20 */ null,
    /* X21 */ null,
    /* X23 */ null,
    /* X27 */ null,
    /* X28 */ null,
    /* X34 */ null,
    /* X35 */ null,
    /* Label */ h2o_nn_16x16x6_ReLU_04_ColInfo_13.VALUES
  };
  // Prior class distribution
  public static final double[] PRIOR_CLASS_DISTRIB = {0.24528301886792453,0.12264150943396226,0.12264150943396226,0.1320754716981132,0.24528301886792453,0.1320754716981132};
  // Class distribution used for model building
  public static final double[] MODEL_CLASS_DISTRIB = null;

  public h2o_nn_16x16x6_ReLU_04() { super(NAMES,DOMAINS); }
  public String getUUID() { return Long.toString(822087262351246736L); }

  // Pass in data in a double[], pre-aligned to the Model's requirements.
  // Jam predictions into the preds[] array; preds[0] is reserved for the
  // main prediction (class for classifiers or value for regression),
  // and remaining columns hold a probability distribution for classifiers.
  public final double[] score0( double[] data, double[] preds ) {
    java.util.Arrays.fill(preds,0);
    java.util.Arrays.fill(NUMS,0);
    int i = 0, ncats = 0;
    final int n = data.length;
    for(; i<n; ++i) {
      NUMS[i] = Double.isNaN(data[i]) ? 0 : data[i];
    }
    java.util.Arrays.fill(ACTIVATION[0],0);
    for (i=0; i<NUMS.length; ++i) {
      ACTIVATION[0][CATOFFSETS[CATOFFSETS.length-1] + i] = Double.isNaN(NUMS[i]) ? 0 : NUMS[i];
    }
    for (i=1; i<ACTIVATION.length; ++i) {
      java.util.Arrays.fill(ACTIVATION[i],0);
      int cols = ACTIVATION[i-1].length;
      int rows = ACTIVATION[i].length;
      int extra=cols-cols%8;
      int multiple = (cols/8)*8-1;
      int idx = 0;
      float[] a = WEIGHT[i];
      double[] x = ACTIVATION[i-1];
      double[] y = BIAS[i];
      double[] res = ACTIVATION[i];
      for (int row=0; row<rows; ++row) {
        double psum0 = 0, psum1 = 0, psum2 = 0, psum3 = 0, psum4 = 0, psum5 = 0, psum6 = 0, psum7 = 0;
        for (int col = 0; col < multiple; col += 8) {
          int off = idx + col;
          psum0 += a[off    ] * x[col    ];
          psum1 += a[off + 1] * x[col + 1];
          psum2 += a[off + 2] * x[col + 2];
          psum3 += a[off + 3] * x[col + 3];
          psum4 += a[off + 4] * x[col + 4];
          psum5 += a[off + 5] * x[col + 5];
          psum6 += a[off + 6] * x[col + 6];
          psum7 += a[off + 7] * x[col + 7];
        }
        res[row] += psum0 + psum1 + psum2 + psum3;
        res[row] += psum4 + psum5 + psum6 + psum7;
        for (int col = extra; col < cols; col++)
          res[row] += a[idx + col] * x[col];
        res[row] += y[row];
        idx += cols;
      }
      if (i<ACTIVATION.length-1) {
        for (int r=0; r<ACTIVATION[i].length; ++r) {
          ACTIVATION[i][r] = Math.max(0, ACTIVATION[i][r]);
        }
      }
      if (i == ACTIVATION.length-1) {
        double max = ACTIVATION[i][0];
        for (int r=1; r<ACTIVATION[i].length; r++) {
          if (ACTIVATION[i][r]>max) max = ACTIVATION[i][r];
        }
        double scale = 0;
        for (int r=0; r<ACTIVATION[i].length; r++) {
          ACTIVATION[i][r] = Math.exp(ACTIVATION[i][r] - max);
          scale += ACTIVATION[i][r];
        }
        for (int r=0; r<ACTIVATION[i].length; r++) {
          if (Double.isNaN(ACTIVATION[i][r]))
            throw new RuntimeException("Numerical instability, predicted NaN.");
          ACTIVATION[i][r] /= scale;
          preds[r+1] = ACTIVATION[i][r];
        }
      }
    }
    preds[0] = hex.genmodel.GenModel.getPrediction(preds, PRIOR_CLASS_DISTRIB, data, 0.5);
    return preds;
  }
}
// Neuron activation values for Input layer
class h2o_nn_16x16x6_ReLU_04_Activation_0 implements java.io.Serializable {
  public static final double[] VALUES = new double[13];
  static {
    h2o_nn_16x16x6_ReLU_04_Activation_0_0.fill(VALUES);
  }
  static final class h2o_nn_16x16x6_ReLU_04_Activation_0_0 implements java.io.Serializable {
    static final void fill(double[] sa) {
      sa[0] = 0.0;
      sa[1] = 0.0;
      sa[2] = 0.0;
      sa[3] = 0.0;
      sa[4] = 0.0;
      sa[5] = 0.0;
      sa[6] = 0.0;
      sa[7] = 0.0;
      sa[8] = 0.0;
      sa[9] = 0.0;
      sa[10] = 0.0;
      sa[11] = 0.0;
      sa[12] = 0.0;
    }
  }
}
// Neuron activation values for Rectifier layer
class h2o_nn_16x16x6_ReLU_04_Activation_1 implements java.io.Serializable {
  public static final double[] VALUES = new double[16];
  static {
    h2o_nn_16x16x6_ReLU_04_Activation_1_0.fill(VALUES);
  }
  static final class h2o_nn_16x16x6_ReLU_04_Activation_1_0 implements java.io.Serializable {
    static final void fill(double[] sa) {
      sa[0] = 0.0;
      sa[1] = 0.0;
      sa[2] = 0.0;
      sa[3] = 0.0;
      sa[4] = 0.0;
      sa[5] = 0.0;
      sa[6] = 0.0;
      sa[7] = 0.0;
      sa[8] = 0.0;
      sa[9] = 0.0;
      sa[10] = 0.0;
      sa[11] = 0.0;
      sa[12] = 0.0;
      sa[13] = 0.0;
      sa[14] = 0.0;
      sa[15] = 0.0;
    }
  }
}
// Neuron activation values for Rectifier layer
class h2o_nn_16x16x6_ReLU_04_Activation_2 implements java.io.Serializable {
  public static final double[] VALUES = new double[16];
  static {
    h2o_nn_16x16x6_ReLU_04_Activation_2_0.fill(VALUES);
  }
  static final class h2o_nn_16x16x6_ReLU_04_Activation_2_0 implements java.io.Serializable {
    static final void fill(double[] sa) {
      sa[0] = 0.0;
      sa[1] = 0.0;
      sa[2] = 0.0;
      sa[3] = 0.0;
      sa[4] = 0.0;
      sa[5] = 0.0;
      sa[6] = 0.0;
      sa[7] = 0.0;
      sa[8] = 0.0;
      sa[9] = 0.0;
      sa[10] = 0.0;
      sa[11] = 0.0;
      sa[12] = 0.0;
      sa[13] = 0.0;
      sa[14] = 0.0;
      sa[15] = 0.0;
    }
  }
}
// Neuron activation values for Softmax layer
class h2o_nn_16x16x6_ReLU_04_Activation_3 implements java.io.Serializable {
  public static final double[] VALUES = new double[6];
  static {
    h2o_nn_16x16x6_ReLU_04_Activation_3_0.fill(VALUES);
  }
  static final class h2o_nn_16x16x6_ReLU_04_Activation_3_0 implements java.io.Serializable {
    static final void fill(double[] sa) {
      sa[0] = 0.0;
      sa[1] = 0.0;
      sa[2] = 0.0;
      sa[3] = 0.0;
      sa[4] = 0.0;
      sa[5] = 0.0;
    }
  }
}
// Neuron bias values for Input layer
class h2o_nn_16x16x6_ReLU_04_Bias_0 implements java.io.Serializable {
  public static final double[] VALUES = null;
}
// Neuron bias values for Rectifier layer
class h2o_nn_16x16x6_ReLU_04_Bias_1 implements java.io.Serializable {
  public static final double[] VALUES = new double[16];
  static {
    h2o_nn_16x16x6_ReLU_04_Bias_1_0.fill(VALUES);
  }
  static final class h2o_nn_16x16x6_ReLU_04_Bias_1_0 implements java.io.Serializable {
    static final void fill(double[] sa) {
      sa[0] = 0.5725706461049862;
      sa[1] = 0.8431061516451313;
      sa[2] = 0.35459041487357573;
      sa[3] = 0.4310593971883103;
      sa[4] = 0.46302911154080956;
      sa[5] = 0.688448122635269;
      sa[6] = 0.48180605088189493;
      sa[7] = 0.707214135644326;
      sa[8] = 0.6598996911870862;
      sa[9] = 0.663076088312993;
      sa[10] = 0.45363480272979945;
      sa[11] = 0.5156228223870581;
      sa[12] = 0.3081669306125096;
      sa[13] = 0.3502295825842248;
      sa[14] = 0.5860524910250977;
      sa[15] = 0.496661259257631;
    }
  }
}
// Neuron bias values for Rectifier layer
class h2o_nn_16x16x6_ReLU_04_Bias_2 implements java.io.Serializable {
  public static final double[] VALUES = new double[16];
  static {
    h2o_nn_16x16x6_ReLU_04_Bias_2_0.fill(VALUES);
  }
  static final class h2o_nn_16x16x6_ReLU_04_Bias_2_0 implements java.io.Serializable {
    static final void fill(double[] sa) {
      sa[0] = 1.0669229668762263;
      sa[1] = 1.1012277700882758;
      sa[2] = 0.8914646953870142;
      sa[3] = 0.9831930617797833;
      sa[4] = 0.9205052991062918;
      sa[5] = 0.9572258678031856;
      sa[6] = 0.9830484787586673;
      sa[7] = 0.9694668633056942;
      sa[8] = 0.9349613500746611;
      sa[9] = 1.068918554317185;
      sa[10] = 0.870260852266009;
      sa[11] = 1.1375423667196605;
      sa[12] = 1.015683479771837;
      sa[13] = 1.07206672537195;
      sa[14] = 0.9367313552553936;
      sa[15] = 0.9679445402454181;
    }
  }
}
// Neuron bias values for Softmax layer
class h2o_nn_16x16x6_ReLU_04_Bias_3 implements java.io.Serializable {
  public static final double[] VALUES = new double[6];
  static {
    h2o_nn_16x16x6_ReLU_04_Bias_3_0.fill(VALUES);
  }
  static final class h2o_nn_16x16x6_ReLU_04_Bias_3_0 implements java.io.Serializable {
    static final void fill(double[] sa) {
      sa[0] = -0.07258024533752638;
      sa[1] = 0.03416983601697788;
      sa[2] = -0.01430311125610827;
      sa[3] = -0.01117772094656367;
      sa[4] = 0.05360341986577745;
      sa[5] = -0.10006709134264333;
    }
  }
}
class h2o_nn_16x16x6_ReLU_04_Weight_0 implements java.io.Serializable {
  public static final float[] VALUES = null;
}
// Neuron weights connecting Input and Rectifier layer
class h2o_nn_16x16x6_ReLU_04_Weight_1 implements java.io.Serializable {
  public static final float[] VALUES = new float[208];
  static {
    h2o_nn_16x16x6_ReLU_04_Weight_1_0.fill(VALUES);
  }
  static final class h2o_nn_16x16x6_ReLU_04_Weight_1_0 implements java.io.Serializable {
    static final void fill(float[] sa) {
      sa[0] = 0.2076736f;
      sa[1] = 0.33246788f;
      sa[2] = 0.22148442f;
      sa[3] = 0.16651177f;
      sa[4] = -0.03905089f;
      sa[5] = -0.21442576f;
      sa[6] = -0.31769875f;
      sa[7] = 0.4019015f;
      sa[8] = 0.26888973f;
      sa[9] = -0.20536412f;
      sa[10] = 0.006138878f;
      sa[11] = -0.296605f;
      sa[12] = 0.3146583f;
      sa[13] = -0.25732f;
      sa[14] = -0.6049435f;
      sa[15] = 0.024855213f;
      sa[16] = -0.02493587f;
      sa[17] = 0.004696317f;
      sa[18] = -0.24155352f;
      sa[19] = 0.043336254f;
      sa[20] = 0.47745988f;
      sa[21] = -0.31368858f;
      sa[22] = 0.49289393f;
      sa[23] = -0.09628234f;
      sa[24] = 0.27625468f;
      sa[25] = 0.4331888f;
      sa[26] = -0.47772112f;
      sa[27] = 0.4368472f;
      sa[28] = 0.31089795f;
      sa[29] = -0.3967917f;
      sa[30] = -0.33336452f;
      sa[31] = 0.19488057f;
      sa[32] = 0.5106929f;
      sa[33] = -0.48930568f;
      sa[34] = 0.088798836f;
      sa[35] = -0.19956592f;
      sa[36] = 0.01190789f;
      sa[37] = 0.40925896f;
      sa[38] = -0.29265863f;
      sa[39] = 0.25859714f;
      sa[40] = 0.07899826f;
      sa[41] = -0.19648841f;
      sa[42] = -0.35457265f;
      sa[43] = -0.11754297f;
      sa[44] = 0.44265115f;
      sa[45] = -0.4609078f;
      sa[46] = 0.010629242f;
      sa[47] = 0.026210984f;
      sa[48] = 0.34282413f;
      sa[49] = 0.3455521f;
      sa[50] = 0.37640995f;
      sa[51] = -0.5043841f;
      sa[52] = -0.13449956f;
      sa[53] = 0.3917418f;
      sa[54] = 0.27594328f;
      sa[55] = -0.09260253f;
      sa[56] = -0.37478065f;
      sa[57] = -0.28096777f;
      sa[58] = 0.32234627f;
      sa[59] = -0.29619035f;
      sa[60] = -0.42385474f;
      sa[61] = 0.3078956f;
      sa[62] = -0.04699479f;
      sa[63] = 0.08312849f;
      sa[64] = 0.09150631f;
      sa[65] = 0.19541173f;
      sa[66] = 0.22611754f;
      sa[67] = 0.36280498f;
      sa[68] = 0.060187764f;
      sa[69] = 0.29929554f;
      sa[70] = -0.17813066f;
      sa[71] = 0.2289206f;
      sa[72] = -0.13016032f;
      sa[73] = 0.32660845f;
      sa[74] = -0.21839854f;
      sa[75] = -0.08381558f;
      sa[76] = -0.25096905f;
      sa[77] = -0.25219563f;
      sa[78] = -0.15155819f;
      sa[79] = 0.32880226f;
      sa[80] = -0.24765813f;
      sa[81] = -0.059920967f;
      sa[82] = -0.12926659f;
      sa[83] = 0.20579621f;
      sa[84] = -0.072640546f;
      sa[85] = -0.25404623f;
      sa[86] = 0.2002394f;
      sa[87] = 0.39468732f;
      sa[88] = 0.10309842f;
      sa[89] = 0.0875494f;
      sa[90] = -0.23874006f;
      sa[91] = 0.28326753f;
      sa[92] = 0.3096619f;
      sa[93] = -0.3090808f;
      sa[94] = -0.39773527f;
      sa[95] = -0.44869694f;
      sa[96] = 0.34265646f;
      sa[97] = -0.23226528f;
      sa[98] = 0.3943364f;
      sa[99] = -0.08852087f;
      sa[100] = 0.022740196f;
      sa[101] = -0.5062692f;
      sa[102] = -0.49357152f;
      sa[103] = 0.024921926f;
      sa[104] = 0.053754974f;
      sa[105] = -0.5548091f;
      sa[106] = -0.20417462f;
      sa[107] = 0.17283198f;
      sa[108] = 0.24189138f;
      sa[109] = -0.2690667f;
      sa[110] = -0.4294671f;
      sa[111] = 0.2983755f;
      sa[112] = 0.27524585f;
      sa[113] = 0.1666708f;
      sa[114] = -0.14691323f;
      sa[115] = 0.07356119f;
      sa[116] = -0.43136835f;
      sa[117] = 0.0747722f;
      sa[118] = -0.51702803f;
      sa[119] = -0.29236263f;
      sa[120] = 0.036169488f;
      sa[121] = 0.22228289f;
      sa[122] = 0.50833446f;
      sa[123] = 0.23893687f;
      sa[124] = 0.4403068f;
      sa[125] = 0.4844022f;
      sa[126] = -0.35340723f;
      sa[127] = -0.094323814f;
      sa[128] = 0.046924707f;
      sa[129] = 0.44543445f;
      sa[130] = -0.22521922f;
      sa[131] = 0.6111795f;
      sa[132] = 0.26902455f;
      sa[133] = -0.4219807f;
      sa[134] = 0.11769765f;
      sa[135] = -0.2992068f;
      sa[136] = -0.37150952f;
      sa[137] = -0.050057415f;
      sa[138] = 0.13555177f;
      sa[139] = -0.12463409f;
      sa[140] = -0.30335602f;
      sa[141] = -0.17150354f;
      sa[142] = 0.16049683f;
      sa[143] = -0.41215092f;
      sa[144] = 0.4894567f;
      sa[145] = -0.18182367f;
      sa[146] = -0.22371578f;
      sa[147] = 0.40712717f;
      sa[148] = 0.14549124f;
      sa[149] = 0.4681242f;
      sa[150] = 0.4305911f;
      sa[151] = -0.38230857f;
      sa[152] = -0.024757238f;
      sa[153] = 0.46340406f;
      sa[154] = 0.26115316f;
      sa[155] = -0.228054f;
      sa[156] = 0.061777193f;
      sa[157] = -0.19784173f;
      sa[158] = 0.07825665f;
      sa[159] = 0.059731275f;
      sa[160] = -0.035664033f;
      sa[161] = 0.34151897f;
      sa[162] = -0.0026172395f;
      sa[163] = -0.19299835f;
      sa[164] = 0.26920444f;
      sa[165] = -0.07352569f;
      sa[166] = -0.41104987f;
      sa[167] = -0.20458998f;
      sa[168] = 0.28948507f;
      sa[169] = 0.4220747f;
      sa[170] = -0.23017432f;
      sa[171] = -0.17167987f;
      sa[172] = -0.23413455f;
      sa[173] = -0.2764691f;
      sa[174] = -0.0113611445f;
      sa[175] = -0.16660409f;
      sa[176] = -0.11068249f;
      sa[177] = -0.082193494f;
      sa[178] = -0.05101313f;
      sa[179] = 0.39418337f;
      sa[180] = -0.0369135f;
      sa[181] = -0.3375717f;
      sa[182] = -0.113597855f;
      sa[183] = 0.33055094f;
      sa[184] = 0.49352708f;
      sa[185] = 0.32099596f;
      sa[186] = -0.24023433f;
      sa[187] = 0.121705055f;
      sa[188] = -0.27225593f;
      sa[189] = 0.3725603f;
      sa[190] = 0.0968178f;
      sa[191] = -0.010692683f;
      sa[192] = -0.25117022f;
      sa[193] = 0.41406292f;
      sa[194] = -0.003338382f;
      sa[195] = 0.44757426f;
      sa[196] = 0.37459603f;
      sa[197] = -0.1364749f;
      sa[198] = -0.033698447f;
      sa[199] = -0.12620977f;
      sa[200] = 0.12898254f;
      sa[201] = -0.56933993f;
      sa[202] = 0.19131613f;
      sa[203] = -0.007740939f;
      sa[204] = -0.20876087f;
      sa[205] = 0.4335183f;
      sa[206] = 0.35107914f;
      sa[207] = 0.2819699f;
    }
  }
}
// Neuron weights connecting Rectifier and Rectifier layer
class h2o_nn_16x16x6_ReLU_04_Weight_2 implements java.io.Serializable {
  public static final float[] VALUES = new float[256];
  static {
    h2o_nn_16x16x6_ReLU_04_Weight_2_0.fill(VALUES);
  }
  static final class h2o_nn_16x16x6_ReLU_04_Weight_2_0 implements java.io.Serializable {
    static final void fill(float[] sa) {
      sa[0] = 0.47248474f;
      sa[1] = 0.0083315205f;
      sa[2] = -0.25302857f;
      sa[3] = -0.39420927f;
      sa[4] = 0.085064396f;
      sa[5] = 0.15973179f;
      sa[6] = 0.2680611f;
      sa[7] = -0.12557265f;
      sa[8] = -0.27768657f;
      sa[9] = 0.26900098f;
      sa[10] = 0.044808153f;
      sa[11] = 0.05350225f;
      sa[12] = 0.14413157f;
      sa[13] = -0.023698816f;
      sa[14] = -0.37695178f;
      sa[15] = 0.33070797f;
      sa[16] = 0.55947196f;
      sa[17] = -0.09679765f;
      sa[18] = 0.010822594f;
      sa[19] = -0.087043524f;
      sa[20] = 0.37820002f;
      sa[21] = 0.095124215f;
      sa[22] = -0.2161623f;
      sa[23] = 0.31317973f;
      sa[24] = -0.26146966f;
      sa[25] = 0.12742859f;
      sa[26] = 0.07393278f;
      sa[27] = 0.4561468f;
      sa[28] = -0.34062645f;
      sa[29] = -0.098784216f;
      sa[30] = 0.21110487f;
      sa[31] = -0.022205219f;
      sa[32] = -0.37158835f;
      sa[33] = -0.53009903f;
      sa[34] = -0.0031059452f;
      sa[35] = 0.30895245f;
      sa[36] = -0.099338576f;
      sa[37] = -0.042970467f;
      sa[38] = -0.00828949f;
      sa[39] = 0.14143854f;
      sa[40] = -0.29760212f;
      sa[41] = -0.47226465f;
      sa[42] = -0.30041787f;
      sa[43] = -0.38391685f;
      sa[44] = -0.062191773f;
      sa[45] = -0.4307454f;
      sa[46] = 0.26398212f;
      sa[47] = 0.29928482f;
      sa[48] = -0.34025013f;
      sa[49] = -0.3030365f;
      sa[50] = 0.1258229f;
      sa[51] = -0.20479509f;
      sa[52] = 0.26350188f;
      sa[53] = 0.263936f;
      sa[54] = -0.11743581f;
      sa[55] = 0.35037225f;
      sa[56] = -0.25561625f;
      sa[57] = -0.31727216f;
      sa[58] = 0.05078281f;
      sa[59] = -0.16125678f;
      sa[60] = 0.36200947f;
      sa[61] = -0.21417256f;
      sa[62] = -0.052594047f;
      sa[63] = 0.024042428f;
      sa[64] = 0.32445621f;
      sa[65] = -0.21754637f;
      sa[66] = 0.21243413f;
      sa[67] = 0.4107484f;
      sa[68] = 0.16920766f;
      sa[69] = -0.33645424f;
      sa[70] = -0.43413115f;
      sa[71] = -0.15494616f;
      sa[72] = -0.4336563f;
      sa[73] = 0.28905454f;
      sa[74] = 0.30212483f;
      sa[75] = -0.013946199f;
      sa[76] = 0.2137205f;
      sa[77] = 0.112133905f;
      sa[78] = -0.40835267f;
      sa[79] = 0.20623796f;
      sa[80] = -0.23359497f;
      sa[81] = 0.06561973f;
      sa[82] = 0.18873435f;
      sa[83] = -0.2174624f;
      sa[84] = -0.4466612f;
      sa[85] = -0.3293112f;
      sa[86] = 0.010872078f;
      sa[87] = 0.26081866f;
      sa[88] = -0.4169938f;
      sa[89] = -0.14248927f;
      sa[90] = -0.33572483f;
      sa[91] = 0.386449f;
      sa[92] = -0.11982084f;
      sa[93] = 0.056717098f;
      sa[94] = -0.49304968f;
      sa[95] = -0.09172832f;
      sa[96] = -0.2504222f;
      sa[97] = -0.017660132f;
      sa[98] = -0.06007165f;
      sa[99] = -0.047175575f;
      sa[100] = -0.2898388f;
      sa[101] = -0.05636247f;
      sa[102] = 0.28621444f;
      sa[103] = -5.7488645E-4f;
      sa[104] = -0.08279258f;
      sa[105] = -0.1628166f;
      sa[106] = 0.43151405f;
      sa[107] = 0.27454567f;
      sa[108] = 0.19410893f;
      sa[109] = -0.05851428f;
      sa[110] = 0.14041296f;
      sa[111] = -0.3182947f;
      sa[112] = -0.37026685f;
      sa[113] = 0.051348984f;
      sa[114] = 0.07875086f;
      sa[115] = -0.130001f;
      sa[116] = 0.37194955f;
      sa[117] = 0.09099273f;
      sa[118] = -0.38519368f;
      sa[119] = -0.24125081f;
      sa[120] = -0.058582008f;
      sa[121] = 0.29498136f;
      sa[122] = -0.15732786f;
      sa[123] = 0.067681305f;
      sa[124] = -0.25079846f;
      sa[125] = 0.20703699f;
      sa[126] = -0.31028208f;
      sa[127] = -0.04986401f;
      sa[128] = -0.38796434f;
      sa[129] = 0.15965585f;
      sa[130] = -0.026305104f;
      sa[131] = 0.2922293f;
      sa[132] = 0.07502671f;
      sa[133] = 0.06349897f;
      sa[134] = 0.20389548f;
      sa[135] = -0.29851443f;
      sa[136] = 0.1767851f;
      sa[137] = -0.2931676f;
      sa[138] = -0.14641619f;
      sa[139] = 0.31583962f;
      sa[140] = -0.18747574f;
      sa[141] = 0.004714548f;
      sa[142] = 0.1365809f;
      sa[143] = -0.3584292f;
      sa[144] = 0.20998743f;
      sa[145] = -0.103081115f;
      sa[146] = 0.062029302f;
      sa[147] = 0.10765102f;
      sa[148] = -0.30885845f;
      sa[149] = 0.26398277f;
      sa[150] = -0.19173853f;
      sa[151] = -0.45807743f;
      sa[152] = 0.5963722f;
      sa[153] = -0.23519069f;
      sa[154] = 0.3375341f;
      sa[155] = -0.33743742f;
      sa[156] = -0.41068456f;
      sa[157] = -0.21794106f;
      sa[158] = 0.081894554f;
      sa[159] = -0.03364249f;
      sa[160] = 0.23939948f;
      sa[161] = -0.35215363f;
      sa[162] = 0.45416266f;
      sa[163] = -0.29313904f;
      sa[164] = 0.17269427f;
      sa[165] = -0.1894311f;
      sa[166] = 0.28980651f;
      sa[167] = -0.44417006f;
      sa[168] = 0.20499077f;
      sa[169] = -0.4486898f;
      sa[170] = 0.17494382f;
      sa[171] = 0.15979567f;
      sa[172] = 0.34174803f;
      sa[173] = 0.3257293f;
      sa[174] = -0.07808717f;
      sa[175] = -0.31029075f;
      sa[176] = -0.093793005f;
      sa[177] = 0.5978705f;
      sa[178] = -0.3493853f;
      sa[179] = -0.06932712f;
      sa[180] = -0.3510029f;
      sa[181] = -0.26478502f;
      sa[182] = 0.10246872f;
      sa[183] = 0.02694555f;
      sa[184] = 0.42857283f;
      sa[185] = 0.51745737f;
      sa[186] = -0.060109705f;
      sa[187] = -0.4093693f;
      sa[188] = 0.042501748f;
      sa[189] = -0.15124705f;
      sa[190] = -0.33451962f;
      sa[191] = -0.39079547f;
      sa[192] = -0.09436353f;
      sa[193] = 0.15608642f;
      sa[194] = -0.20993754f;
      sa[195] = -0.06886061f;
      sa[196] = 0.120008044f;
      sa[197] = -0.26227975f;
      sa[198] = 0.0962051f;
      sa[199] = 0.44615734f;
      sa[200] = 0.009727889f;
      sa[201] = 0.23763563f;
      sa[202] = 0.15002298f;
      sa[203] = -0.34906298f;
      sa[204] = 0.13682823f;
      sa[205] = 0.45279598f;
      sa[206] = -0.06315759f;
      sa[207] = 0.23761317f;
      sa[208] = -0.11940282f;
      sa[209] = 0.24966529f;
      sa[210] = -0.1263784f;
      sa[211] = -0.34564567f;
      sa[212] = -0.2949121f;
      sa[213] = 0.1830024f;
      sa[214] = -0.36642095f;
      sa[215] = -0.098397575f;
      sa[216] = 0.14018983f;
      sa[217] = 0.46776494f;
      sa[218] = 0.025788978f;
      sa[219] = 0.11319006f;
      sa[220] = 0.15773226f;
      sa[221] = -0.036906525f;
      sa[222] = -0.3829181f;
      sa[223] = -0.31897044f;
      sa[224] = 0.26662558f;
      sa[225] = 0.057298947f;
      sa[226] = -0.12669335f;
      sa[227] = -0.04018257f;
      sa[228] = -0.15618335f;
      sa[229] = -0.19496714f;
      sa[230] = -0.33841002f;
      sa[231] = -0.29780078f;
      sa[232] = 0.33176407f;
      sa[233] = -0.13498953f;
      sa[234] = -0.22983786f;
      sa[235] = 0.03314737f;
      sa[236] = -0.40961137f;
      sa[237] = 0.3754281f;
      sa[238] = 0.024441205f;
      sa[239] = -0.040271387f;
      sa[240] = -0.16256323f;
      sa[241] = -0.3995462f;
      sa[242] = -0.22718945f;
      sa[243] = 0.5187609f;
      sa[244] = 0.13613702f;
      sa[245] = 0.2743058f;
      sa[246] = 0.23711699f;
      sa[247] = -0.44644758f;
      sa[248] = -0.18310161f;
      sa[249] = -0.0646825f;
      sa[250] = 0.19478585f;
      sa[251] = 0.5625449f;
      sa[252] = 0.1411083f;
      sa[253] = -0.2778617f;
      sa[254] = 0.38607457f;
      sa[255] = 0.35390863f;
    }
  }
}
// Neuron weights connecting Rectifier and Softmax layer
class h2o_nn_16x16x6_ReLU_04_Weight_3 implements java.io.Serializable {
  public static final float[] VALUES = new float[96];
  static {
    h2o_nn_16x16x6_ReLU_04_Weight_3_0.fill(VALUES);
  }
  static final class h2o_nn_16x16x6_ReLU_04_Weight_3_0 implements java.io.Serializable {
    static final void fill(float[] sa) {
      sa[0] = -0.012037795f;
      sa[1] = -1.6037153f;
      sa[2] = -1.5582694f;
      sa[3] = 1.2606035f;
      sa[4] = 0.34942937f;
      sa[5] = -0.20072077f;
      sa[6] = -1.6421645f;
      sa[7] = 1.4364324f;
      sa[8] = 1.7589598f;
      sa[9] = 0.056549132f;
      sa[10] = 1.5810744f;
      sa[11] = 1.238167f;
      sa[12] = 1.7781166f;
      sa[13] = -0.6921675f;
      sa[14] = -1.9213301f;
      sa[15] = -0.7302109f;
      sa[16] = 0.75566894f;
      sa[17] = -0.72336376f;
      sa[18] = -1.4607177f;
      sa[19] = -0.8710919f;
      sa[20] = -1.8829646f;
      sa[21] = 0.31516328f;
      sa[22] = -1.9115242f;
      sa[23] = -0.6322044f;
      sa[24] = -0.5074027f;
      sa[25] = 1.8828559f;
      sa[26] = -0.31588426f;
      sa[27] = 1.2308792f;
      sa[28] = 1.2212787f;
      sa[29] = -0.786279f;
      sa[30] = 0.20345724f;
      sa[31] = 0.177512f;
      sa[32] = 0.36091125f;
      sa[33] = 0.2664332f;
      sa[34] = -0.55560493f;
      sa[35] = 0.9852437f;
      sa[36] = 0.5338876f;
      sa[37] = -1.3152094f;
      sa[38] = 0.5820507f;
      sa[39] = -0.29465985f;
      sa[40] = 0.26315093f;
      sa[41] = -0.6784124f;
      sa[42] = 0.5464192f;
      sa[43] = -1.4083784f;
      sa[44] = 0.89600956f;
      sa[45] = -2.3106172f;
      sa[46] = -2.0627573f;
      sa[47] = 0.090969205f;
      sa[48] = 1.6439661f;
      sa[49] = -0.22930774f;
      sa[50] = -0.5186572f;
      sa[51] = 1.7757195f;
      sa[52] = -1.6778837f;
      sa[53] = 0.88698834f;
      sa[54] = 1.7264931f;
      sa[55] = 1.1014987f;
      sa[56] = -0.62997794f;
      sa[57] = -0.003842305f;
      sa[58] = 1.0158259f;
      sa[59] = 0.87736833f;
      sa[60] = -1.3686125f;
      sa[61] = 1.0002829f;
      sa[62] = -0.4205389f;
      sa[63] = -0.8605303f;
      sa[64] = 0.96365756f;
      sa[65] = -0.86760724f;
      sa[66] = -1.7334251f;
      sa[67] = -0.091185115f;
      sa[68] = 0.92157465f;
      sa[69] = -1.3292534f;
      sa[70] = -1.5850636f;
      sa[71] = -0.07151921f;
      sa[72] = -1.0237458f;
      sa[73] = -1.180394f;
      sa[74] = -1.0815334f;
      sa[75] = 1.490728f;
      sa[76] = 1.9224114f;
      sa[77] = -0.5347964f;
      sa[78] = -1.392577f;
      sa[79] = -0.3710102f;
      sa[80] = 0.58722085f;
      sa[81] = -1.7226895f;
      sa[82] = -0.23063998f;
      sa[83] = -1.433148f;
      sa[84] = 1.5338918f;
      sa[85] = 1.0805041f;
      sa[86] = -1.9870067f;
      sa[87] = 1.1233673f;
      sa[88] = -1.6107332f;
      sa[89] = -1.0080783f;
      sa[90] = 0.2124946f;
      sa[91] = 0.08862238f;
      sa[92] = 1.2674297f;
      sa[93] = 1.9066141f;
      sa[94] = 1.5004845f;
      sa[95] = 0.6210319f;
    }
  }
}
// The class representing training column names
class NamesHolder_h2o_nn_16x16x6_ReLU_04 implements java.io.Serializable {
  public static final String[] VALUES = new String[13];
  static {
    NamesHolder_h2o_nn_16x16x6_ReLU_04_0.fill(VALUES);
  }
  static final class NamesHolder_h2o_nn_16x16x6_ReLU_04_0 implements java.io.Serializable {
    static final void fill(String[] sa) {
      sa[0] = "X5";
      sa[1] = "X12";
      sa[2] = "X15";
      sa[3] = "X17";
      sa[4] = "X18";
      sa[5] = "X19";
      sa[6] = "X20";
      sa[7] = "X21";
      sa[8] = "X23";
      sa[9] = "X27";
      sa[10] = "X28";
      sa[11] = "X34";
      sa[12] = "X35";
    }
  }
}
// The class representing column Label
class h2o_nn_16x16x6_ReLU_04_ColInfo_13 implements java.io.Serializable {
  public static final String[] VALUES = new String[6];
  static {
    h2o_nn_16x16x6_ReLU_04_ColInfo_13_0.fill(VALUES);
  }
  static final class h2o_nn_16x16x6_ReLU_04_ColInfo_13_0 implements java.io.Serializable {
    static final void fill(String[] sa) {
      sa[0] = "1";
      sa[1] = "2";
      sa[2] = "3";
      sa[3] = "4";
      sa[4] = "5";
      sa[5] = "6";
    }
  }
}


