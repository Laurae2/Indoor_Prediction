/*
  Licensed under the Apache License, Version 2.0
    http://www.apache.org/licenses/LICENSE-2.0.html

  AUTOGENERATED BY H2O at 2016-12-26T14:43:09.165+01:00
  3.10.0.8
  
  Standalone prediction code with sample test data for DeepLearningModel named h2o_nn_16x16x6_ReLU_10

  How to download, compile and execute:
      mkdir tmpdir
      cd tmpdir
      curl http://127.0.0.1:54321/3/h2o-genmodel.jar > h2o-genmodel.jar
      curl http://127.0.0.1:54321/3/Models.java/h2o_nn_16x16x6_ReLU_10 > h2o_nn_16x16x6_ReLU_10.java
      javac -cp h2o-genmodel.jar -J-Xmx2g -J-XX:MaxPermSize=128m h2o_nn_16x16x6_ReLU_10.java

     (Note:  Try java argument -XX:+PrintCompilation to show runtime JIT compiler behavior.)
*/
import java.util.Map;
import hex.genmodel.GenModel;
import hex.genmodel.annotations.ModelPojo;

@ModelPojo(name="h2o_nn_16x16x6_ReLU_10", algorithm="deeplearning")
public class h2o_nn_16x16x6_ReLU_10 extends GenModel {
  public hex.ModelCategory getModelCategory() { return hex.ModelCategory.Multinomial; }
  public boolean isSupervised() { return true; }
  public int nfeatures() { return 13; }
  public int nclasses() { return 6; }
  // Thread-local storage for input neuron activation values.
  final double[] NUMS = new double[13];
  static class NORMMUL implements java.io.Serializable {
    public static final double[] VALUES = null;
}
  static class NORMSUB implements java.io.Serializable {
    public static final double[] VALUES = null;
}
  // Workspace for categorical offsets.
  public static final int[] CATOFFSETS = {0};
  // Number of neurons for each layer.
  public static final int[] NEURONS = {13,16,16,6};
    // Thread-local storage for neuron activation values.
    final double[][] ACTIVATION = new double[][] {
      /* Input */ h2o_nn_16x16x6_ReLU_10_Activation_0.VALUES,
      /* Rectifier */ h2o_nn_16x16x6_ReLU_10_Activation_1.VALUES,
      /* Rectifier */ h2o_nn_16x16x6_ReLU_10_Activation_2.VALUES,
      /* Softmax */ h2o_nn_16x16x6_ReLU_10_Activation_3.VALUES
    };
    // Neuron bias values.
    public static final double[][] BIAS = new double[][] {
      /* Input */ h2o_nn_16x16x6_ReLU_10_Bias_0.VALUES,
      /* Rectifier */ h2o_nn_16x16x6_ReLU_10_Bias_1.VALUES,
      /* Rectifier */ h2o_nn_16x16x6_ReLU_10_Bias_2.VALUES,
      /* Softmax */ h2o_nn_16x16x6_ReLU_10_Bias_3.VALUES
    };
    // Connecting weights between neurons.
    public static final float[][] WEIGHT = new float[][] {
      /* Input */ h2o_nn_16x16x6_ReLU_10_Weight_0.VALUES,
      /* Rectifier */ h2o_nn_16x16x6_ReLU_10_Weight_1.VALUES,
      /* Rectifier */ h2o_nn_16x16x6_ReLU_10_Weight_2.VALUES,
      /* Softmax */ h2o_nn_16x16x6_ReLU_10_Weight_3.VALUES
    };

  // Names of columns used by model.
  public static final String[] NAMES = NamesHolder_h2o_nn_16x16x6_ReLU_10.VALUES;
  // Number of output classes included in training data response column.
  public static final int NCLASSES = 6;

  // Column domains. The last array contains domain of response column.
  public static final String[][] DOMAINS = new String[][] {
    /* X5 */ null,
    /* X12 */ null,
    /* X15 */ null,
    /* X17 */ null,
    /* X18 */ null,
    /* X19 */ null,
    /* X20 */ null,
    /* X21 */ null,
    /* X23 */ null,
    /* X27 */ null,
    /* X28 */ null,
    /* X34 */ null,
    /* X35 */ null,
    /* Label */ h2o_nn_16x16x6_ReLU_10_ColInfo_13.VALUES
  };
  // Prior class distribution
  public static final double[] PRIOR_CLASS_DISTRIB = {0.24761904761904763,0.18571428571428572,0.06190476190476191,0.12857142857142856,0.24761904761904763,0.12857142857142856};
  // Class distribution used for model building
  public static final double[] MODEL_CLASS_DISTRIB = null;

  public h2o_nn_16x16x6_ReLU_10() { super(NAMES,DOMAINS); }
  public String getUUID() { return Long.toString(-6197706306111620188L); }

  // Pass in data in a double[], pre-aligned to the Model's requirements.
  // Jam predictions into the preds[] array; preds[0] is reserved for the
  // main prediction (class for classifiers or value for regression),
  // and remaining columns hold a probability distribution for classifiers.
  public final double[] score0( double[] data, double[] preds ) {
    java.util.Arrays.fill(preds,0);
    java.util.Arrays.fill(NUMS,0);
    int i = 0, ncats = 0;
    final int n = data.length;
    for(; i<n; ++i) {
      NUMS[i] = Double.isNaN(data[i]) ? 0 : data[i];
    }
    java.util.Arrays.fill(ACTIVATION[0],0);
    for (i=0; i<NUMS.length; ++i) {
      ACTIVATION[0][CATOFFSETS[CATOFFSETS.length-1] + i] = Double.isNaN(NUMS[i]) ? 0 : NUMS[i];
    }
    for (i=1; i<ACTIVATION.length; ++i) {
      java.util.Arrays.fill(ACTIVATION[i],0);
      int cols = ACTIVATION[i-1].length;
      int rows = ACTIVATION[i].length;
      int extra=cols-cols%8;
      int multiple = (cols/8)*8-1;
      int idx = 0;
      float[] a = WEIGHT[i];
      double[] x = ACTIVATION[i-1];
      double[] y = BIAS[i];
      double[] res = ACTIVATION[i];
      for (int row=0; row<rows; ++row) {
        double psum0 = 0, psum1 = 0, psum2 = 0, psum3 = 0, psum4 = 0, psum5 = 0, psum6 = 0, psum7 = 0;
        for (int col = 0; col < multiple; col += 8) {
          int off = idx + col;
          psum0 += a[off    ] * x[col    ];
          psum1 += a[off + 1] * x[col + 1];
          psum2 += a[off + 2] * x[col + 2];
          psum3 += a[off + 3] * x[col + 3];
          psum4 += a[off + 4] * x[col + 4];
          psum5 += a[off + 5] * x[col + 5];
          psum6 += a[off + 6] * x[col + 6];
          psum7 += a[off + 7] * x[col + 7];
        }
        res[row] += psum0 + psum1 + psum2 + psum3;
        res[row] += psum4 + psum5 + psum6 + psum7;
        for (int col = extra; col < cols; col++)
          res[row] += a[idx + col] * x[col];
        res[row] += y[row];
        idx += cols;
      }
      if (i<ACTIVATION.length-1) {
        for (int r=0; r<ACTIVATION[i].length; ++r) {
          ACTIVATION[i][r] = Math.max(0, ACTIVATION[i][r]);
        }
      }
      if (i == ACTIVATION.length-1) {
        double max = ACTIVATION[i][0];
        for (int r=1; r<ACTIVATION[i].length; r++) {
          if (ACTIVATION[i][r]>max) max = ACTIVATION[i][r];
        }
        double scale = 0;
        for (int r=0; r<ACTIVATION[i].length; r++) {
          ACTIVATION[i][r] = Math.exp(ACTIVATION[i][r] - max);
          scale += ACTIVATION[i][r];
        }
        for (int r=0; r<ACTIVATION[i].length; r++) {
          if (Double.isNaN(ACTIVATION[i][r]))
            throw new RuntimeException("Numerical instability, predicted NaN.");
          ACTIVATION[i][r] /= scale;
          preds[r+1] = ACTIVATION[i][r];
        }
      }
    }
    preds[0] = hex.genmodel.GenModel.getPrediction(preds, PRIOR_CLASS_DISTRIB, data, 0.5);
    return preds;
  }
}
// Neuron activation values for Input layer
class h2o_nn_16x16x6_ReLU_10_Activation_0 implements java.io.Serializable {
  public static final double[] VALUES = new double[13];
  static {
    h2o_nn_16x16x6_ReLU_10_Activation_0_0.fill(VALUES);
  }
  static final class h2o_nn_16x16x6_ReLU_10_Activation_0_0 implements java.io.Serializable {
    static final void fill(double[] sa) {
      sa[0] = 0.0;
      sa[1] = 0.0;
      sa[2] = 0.0;
      sa[3] = 0.0;
      sa[4] = 0.0;
      sa[5] = 0.0;
      sa[6] = 0.0;
      sa[7] = 0.0;
      sa[8] = 0.0;
      sa[9] = 0.0;
      sa[10] = 0.0;
      sa[11] = 0.0;
      sa[12] = 0.0;
    }
  }
}
// Neuron activation values for Rectifier layer
class h2o_nn_16x16x6_ReLU_10_Activation_1 implements java.io.Serializable {
  public static final double[] VALUES = new double[16];
  static {
    h2o_nn_16x16x6_ReLU_10_Activation_1_0.fill(VALUES);
  }
  static final class h2o_nn_16x16x6_ReLU_10_Activation_1_0 implements java.io.Serializable {
    static final void fill(double[] sa) {
      sa[0] = 0.0;
      sa[1] = 0.0;
      sa[2] = 0.0;
      sa[3] = 0.0;
      sa[4] = 0.0;
      sa[5] = 0.0;
      sa[6] = 0.0;
      sa[7] = 0.0;
      sa[8] = 0.0;
      sa[9] = 0.0;
      sa[10] = 0.0;
      sa[11] = 0.0;
      sa[12] = 0.0;
      sa[13] = 0.0;
      sa[14] = 0.0;
      sa[15] = 0.0;
    }
  }
}
// Neuron activation values for Rectifier layer
class h2o_nn_16x16x6_ReLU_10_Activation_2 implements java.io.Serializable {
  public static final double[] VALUES = new double[16];
  static {
    h2o_nn_16x16x6_ReLU_10_Activation_2_0.fill(VALUES);
  }
  static final class h2o_nn_16x16x6_ReLU_10_Activation_2_0 implements java.io.Serializable {
    static final void fill(double[] sa) {
      sa[0] = 0.0;
      sa[1] = 0.0;
      sa[2] = 0.0;
      sa[3] = 0.0;
      sa[4] = 0.0;
      sa[5] = 0.0;
      sa[6] = 0.0;
      sa[7] = 0.0;
      sa[8] = 0.0;
      sa[9] = 0.0;
      sa[10] = 0.0;
      sa[11] = 0.0;
      sa[12] = 0.0;
      sa[13] = 0.0;
      sa[14] = 0.0;
      sa[15] = 0.0;
    }
  }
}
// Neuron activation values for Softmax layer
class h2o_nn_16x16x6_ReLU_10_Activation_3 implements java.io.Serializable {
  public static final double[] VALUES = new double[6];
  static {
    h2o_nn_16x16x6_ReLU_10_Activation_3_0.fill(VALUES);
  }
  static final class h2o_nn_16x16x6_ReLU_10_Activation_3_0 implements java.io.Serializable {
    static final void fill(double[] sa) {
      sa[0] = 0.0;
      sa[1] = 0.0;
      sa[2] = 0.0;
      sa[3] = 0.0;
      sa[4] = 0.0;
      sa[5] = 0.0;
    }
  }
}
// Neuron bias values for Input layer
class h2o_nn_16x16x6_ReLU_10_Bias_0 implements java.io.Serializable {
  public static final double[] VALUES = null;
}
// Neuron bias values for Rectifier layer
class h2o_nn_16x16x6_ReLU_10_Bias_1 implements java.io.Serializable {
  public static final double[] VALUES = new double[16];
  static {
    h2o_nn_16x16x6_ReLU_10_Bias_1_0.fill(VALUES);
  }
  static final class h2o_nn_16x16x6_ReLU_10_Bias_1_0 implements java.io.Serializable {
    static final void fill(double[] sa) {
      sa[0] = 0.6712112702009836;
      sa[1] = 0.7585597741901879;
      sa[2] = 0.31190906425138376;
      sa[3] = 0.485716216630149;
      sa[4] = 0.48246600052361865;
      sa[5] = 0.6265996761641661;
      sa[6] = 0.3320808081931331;
      sa[7] = 0.6145128055091277;
      sa[8] = 0.6383204482822303;
      sa[9] = 0.831653525329303;
      sa[10] = 0.46490423988120727;
      sa[11] = 0.47699613548088;
      sa[12] = 0.31128439444819805;
      sa[13] = 0.4401006759043602;
      sa[14] = 0.5897835867261778;
      sa[15] = 0.3438105846385504;
    }
  }
}
// Neuron bias values for Rectifier layer
class h2o_nn_16x16x6_ReLU_10_Bias_2 implements java.io.Serializable {
  public static final double[] VALUES = new double[16];
  static {
    h2o_nn_16x16x6_ReLU_10_Bias_2_0.fill(VALUES);
  }
  static final class h2o_nn_16x16x6_ReLU_10_Bias_2_0 implements java.io.Serializable {
    static final void fill(double[] sa) {
      sa[0] = 1.160406916993525;
      sa[1] = 1.174134887415464;
      sa[2] = 0.8919467214615927;
      sa[3] = 0.955872386161946;
      sa[4] = 0.8665113538651832;
      sa[5] = 0.9935281041920605;
      sa[6] = 0.8921777800339219;
      sa[7] = 0.9829500699409919;
      sa[8] = 0.9342008652621469;
      sa[9] = 1.053054618212947;
      sa[10] = 0.9081089089222041;
      sa[11] = 1.129805485259238;
      sa[12] = 1.0804957691358894;
      sa[13] = 1.1379267660047734;
      sa[14] = 0.9518973141968299;
      sa[15] = 0.9868447253205669;
    }
  }
}
// Neuron bias values for Softmax layer
class h2o_nn_16x16x6_ReLU_10_Bias_3 implements java.io.Serializable {
  public static final double[] VALUES = new double[6];
  static {
    h2o_nn_16x16x6_ReLU_10_Bias_3_0.fill(VALUES);
  }
  static final class h2o_nn_16x16x6_ReLU_10_Bias_3_0 implements java.io.Serializable {
    static final void fill(double[] sa) {
      sa[0] = -0.08274480892656812;
      sa[1] = 0.03466366834725575;
      sa[2] = -0.0723843883702466;
      sa[3] = -0.05662625313648061;
      sa[4] = 0.07794211962427355;
      sa[5] = -0.11061589700354667;
    }
  }
}
class h2o_nn_16x16x6_ReLU_10_Weight_0 implements java.io.Serializable {
  public static final float[] VALUES = null;
}
// Neuron weights connecting Input and Rectifier layer
class h2o_nn_16x16x6_ReLU_10_Weight_1 implements java.io.Serializable {
  public static final float[] VALUES = new float[208];
  static {
    h2o_nn_16x16x6_ReLU_10_Weight_1_0.fill(VALUES);
  }
  static final class h2o_nn_16x16x6_ReLU_10_Weight_1_0 implements java.io.Serializable {
    static final void fill(float[] sa) {
      sa[0] = 0.17371434f;
      sa[1] = 0.18745674f;
      sa[2] = 0.17276062f;
      sa[3] = 0.21814162f;
      sa[4] = 0.004199943f;
      sa[5] = -0.265359f;
      sa[6] = -0.2203562f;
      sa[7] = 0.47862744f;
      sa[8] = 0.13590153f;
      sa[9] = -0.17789018f;
      sa[10] = 0.09052943f;
      sa[11] = -0.43945527f;
      sa[12] = 0.33550572f;
      sa[13] = -0.32476133f;
      sa[14] = -0.38826555f;
      sa[15] = 0.18869969f;
      sa[16] = -0.051100843f;
      sa[17] = 0.04237571f;
      sa[18] = -0.24193282f;
      sa[19] = 0.07998384f;
      sa[20] = 0.5189731f;
      sa[21] = -0.24071388f;
      sa[22] = 0.40106985f;
      sa[23] = -0.355945f;
      sa[24] = 0.34576097f;
      sa[25] = 0.4292152f;
      sa[26] = -0.41904795f;
      sa[27] = 0.52068293f;
      sa[28] = 0.37312064f;
      sa[29] = -0.39664435f;
      sa[30] = -0.40943098f;
      sa[31] = 0.17077802f;
      sa[32] = 0.47713932f;
      sa[33] = -0.49391642f;
      sa[34] = 0.14549364f;
      sa[35] = -0.13041915f;
      sa[36] = -0.13976395f;
      sa[37] = 0.48183233f;
      sa[38] = -0.24057785f;
      sa[39] = 0.34431005f;
      sa[40] = -4.8342976E-4f;
      sa[41] = -0.23958905f;
      sa[42] = -0.37276602f;
      sa[43] = -0.42960143f;
      sa[44] = 0.39672884f;
      sa[45] = -0.53653926f;
      sa[46] = -0.055094775f;
      sa[47] = -0.03355284f;
      sa[48] = 0.31672204f;
      sa[49] = 0.34321454f;
      sa[50] = 0.40608364f;
      sa[51] = -0.55690455f;
      sa[52] = -0.06726089f;
      sa[53] = 0.32396087f;
      sa[54] = 0.34367582f;
      sa[55] = -0.0922506f;
      sa[56] = -0.40254623f;
      sa[57] = -0.20245574f;
      sa[58] = 0.6242732f;
      sa[59] = -0.30207723f;
      sa[60] = -0.37930354f;
      sa[61] = 0.32589236f;
      sa[62] = -0.15522492f;
      sa[63] = 0.11469246f;
      sa[64] = 0.13981262f;
      sa[65] = 0.12040275f;
      sa[66] = 0.19333403f;
      sa[67] = 0.3343654f;
      sa[68] = -0.0596959f;
      sa[69] = 0.3061414f;
      sa[70] = 0.016996108f;
      sa[71] = 0.22185817f;
      sa[72] = -0.14734533f;
      sa[73] = 0.31429568f;
      sa[74] = -0.10232891f;
      sa[75] = -0.085771784f;
      sa[76] = -0.21794927f;
      sa[77] = -0.19370133f;
      sa[78] = -0.1960686f;
      sa[79] = 0.3276186f;
      sa[80] = -0.24858221f;
      sa[81] = -0.11206811f;
      sa[82] = -0.1396675f;
      sa[83] = 0.32899958f;
      sa[84] = -0.14515474f;
      sa[85] = -0.27018216f;
      sa[86] = 0.22151701f;
      sa[87] = 0.39101338f;
      sa[88] = 0.096643426f;
      sa[89] = 0.22315532f;
      sa[90] = -0.40258616f;
      sa[91] = 0.21636993f;
      sa[92] = 0.075426385f;
      sa[93] = -0.2905367f;
      sa[94] = -0.5097836f;
      sa[95] = -0.47773772f;
      sa[96] = 0.32939243f;
      sa[97] = 0.14466088f;
      sa[98] = 0.45560625f;
      sa[99] = -0.039588664f;
      sa[100] = -0.25459236f;
      sa[101] = -0.4182686f;
      sa[102] = -0.44893453f;
      sa[103] = -0.0654542f;
      sa[104] = 0.05574348f;
      sa[105] = -0.10318775f;
      sa[106] = -0.13470587f;
      sa[107] = 0.41568732f;
      sa[108] = 0.33718228f;
      sa[109] = -0.23858915f;
      sa[110] = -0.6503365f;
      sa[111] = 0.20097545f;
      sa[112] = 0.2239874f;
      sa[113] = 0.23006219f;
      sa[114] = -0.19790015f;
      sa[115] = 0.14919572f;
      sa[116] = -0.39526612f;
      sa[117] = 0.066839285f;
      sa[118] = -0.5842876f;
      sa[119] = -0.31241527f;
      sa[120] = 0.09896991f;
      sa[121] = 0.20789672f;
      sa[122] = 0.41234508f;
      sa[123] = 0.4885592f;
      sa[124] = 0.5315918f;
      sa[125] = 0.49340937f;
      sa[126] = -0.44054717f;
      sa[127] = -0.10291799f;
      sa[128] = -0.062353108f;
      sa[129] = 0.50043327f;
      sa[130] = -0.18284914f;
      sa[131] = 0.6147443f;
      sa[132] = 0.30115038f;
      sa[133] = -0.36765215f;
      sa[134] = 0.09297713f;
      sa[135] = -0.3248489f;
      sa[136] = -0.2632707f;
      sa[137] = -0.06504128f;
      sa[138] = 0.13684759f;
      sa[139] = -0.08260241f;
      sa[140] = -0.39717868f;
      sa[141] = -0.14705686f;
      sa[142] = 0.10245523f;
      sa[143] = -0.4481346f;
      sa[144] = 0.5503347f;
      sa[145] = -0.35168546f;
      sa[146] = -0.35111257f;
      sa[147] = 0.27425307f;
      sa[148] = 0.118258886f;
      sa[149] = 0.34408566f;
      sa[150] = 0.44723225f;
      sa[151] = -0.42233977f;
      sa[152] = -0.26675916f;
      sa[153] = 0.34176835f;
      sa[154] = 0.33433655f;
      sa[155] = -0.31529105f;
      sa[156] = 0.1176638f;
      sa[157] = -0.24818072f;
      sa[158] = 0.10722924f;
      sa[159] = 0.019273365f;
      sa[160] = -0.034567088f;
      sa[161] = 0.28971535f;
      sa[162] = 0.10248854f;
      sa[163] = -0.11222799f;
      sa[164] = 0.38584763f;
      sa[165] = -0.12162859f;
      sa[166] = -0.47965693f;
      sa[167] = -0.15848923f;
      sa[168] = 0.32933173f;
      sa[169] = 0.5311272f;
      sa[170] = -0.13675953f;
      sa[171] = -0.10873397f;
      sa[172] = -0.1289602f;
      sa[173] = -0.17672509f;
      sa[174] = -0.05163006f;
      sa[175] = -0.18447103f;
      sa[176] = -0.15263778f;
      sa[177] = -0.097042054f;
      sa[178] = -0.015971404f;
      sa[179] = 0.4176653f;
      sa[180] = -0.089041136f;
      sa[181] = -0.22841284f;
      sa[182] = -0.18966562f;
      sa[183] = 0.25201842f;
      sa[184] = 0.31270695f;
      sa[185] = 0.39423698f;
      sa[186] = -0.21594658f;
      sa[187] = 0.20248571f;
      sa[188] = -0.41059318f;
      sa[189] = 0.34611621f;
      sa[190] = -0.006102431f;
      sa[191] = -0.008853444f;
      sa[192] = -0.39661297f;
      sa[193] = 0.4539832f;
      sa[194] = -0.16374801f;
      sa[195] = 0.33234262f;
      sa[196] = 0.30110702f;
      sa[197] = -0.21564144f;
      sa[198] = 0.052901387f;
      sa[199] = -0.22040586f;
      sa[200] = 0.10179241f;
      sa[201] = -0.5401003f;
      sa[202] = 0.055935275f;
      sa[203] = -0.173789f;
      sa[204] = -0.23876788f;
      sa[205] = 0.42194897f;
      sa[206] = 0.337288f;
      sa[207] = 0.20868625f;
    }
  }
}
// Neuron weights connecting Rectifier and Rectifier layer
class h2o_nn_16x16x6_ReLU_10_Weight_2 implements java.io.Serializable {
  public static final float[] VALUES = new float[256];
  static {
    h2o_nn_16x16x6_ReLU_10_Weight_2_0.fill(VALUES);
  }
  static final class h2o_nn_16x16x6_ReLU_10_Weight_2_0 implements java.io.Serializable {
    static final void fill(float[] sa) {
      sa[0] = 0.55084306f;
      sa[1] = 0.111165635f;
      sa[2] = -0.36907738f;
      sa[3] = -0.4149415f;
      sa[4] = 0.09072336f;
      sa[5] = 0.20805906f;
      sa[6] = 0.13975914f;
      sa[7] = -0.059188314f;
      sa[8] = -0.31971872f;
      sa[9] = 0.56499773f;
      sa[10] = 0.031796087f;
      sa[11] = 0.074626096f;
      sa[12] = 0.2413056f;
      sa[13] = -0.0049762325f;
      sa[14] = -0.42158446f;
      sa[15] = 0.30840608f;
      sa[16] = 0.6165297f;
      sa[17] = 0.08065606f;
      sa[18] = -0.033471767f;
      sa[19] = -0.078878626f;
      sa[20] = 0.32549876f;
      sa[21] = 0.12422347f;
      sa[22] = -0.1953021f;
      sa[23] = 0.40211505f;
      sa[24] = -0.06985658f;
      sa[25] = 0.24799907f;
      sa[26] = 0.043267775f;
      sa[27] = 0.48438087f;
      sa[28] = -0.32255346f;
      sa[29] = -0.0541763f;
      sa[30] = 0.21345617f;
      sa[31] = -0.03609528f;
      sa[32] = -0.4094248f;
      sa[33] = -0.52003783f;
      sa[34] = -0.020924278f;
      sa[35] = 0.33780652f;
      sa[36] = -0.13166243f;
      sa[37] = -0.060060404f;
      sa[38] = 0.0016962135f;
      sa[39] = 0.1375588f;
      sa[40] = -0.24790658f;
      sa[41] = -0.46988207f;
      sa[42] = -0.3387149f;
      sa[43] = -0.37737054f;
      sa[44] = -0.09011437f;
      sa[45] = -0.41708735f;
      sa[46] = 0.26573673f;
      sa[47] = 0.33298355f;
      sa[48] = -0.29174003f;
      sa[49] = -0.23399483f;
      sa[50] = 0.17619273f;
      sa[51] = -0.18742415f;
      sa[52] = 0.4845585f;
      sa[53] = 0.29069465f;
      sa[54] = -0.15992999f;
      sa[55] = 0.4667532f;
      sa[56] = -0.35694513f;
      sa[57] = -0.26857063f;
      sa[58] = 0.07999129f;
      sa[59] = -0.12787156f;
      sa[60] = 0.40300778f;
      sa[61] = -0.2674208f;
      sa[62] = -0.031910226f;
      sa[63] = -0.016921708f;
      sa[64] = 0.17451431f;
      sa[65] = -0.29891f;
      sa[66] = 0.22303516f;
      sa[67] = 0.42274037f;
      sa[68] = 0.19742116f;
      sa[69] = -0.335811f;
      sa[70] = -0.43276104f;
      sa[71] = -0.16887882f;
      sa[72] = -0.62665564f;
      sa[73] = 0.3077585f;
      sa[74] = 0.2175172f;
      sa[75] = -0.022904836f;
      sa[76] = 0.15866698f;
      sa[77] = 0.11909215f;
      sa[78] = -0.49277708f;
      sa[79] = 0.19100937f;
      sa[80] = -0.20409048f;
      sa[81] = 0.008362372f;
      sa[82] = 0.2022188f;
      sa[83] = -0.14599796f;
      sa[84] = -0.4794752f;
      sa[85] = -0.33878124f;
      sa[86] = 0.057029624f;
      sa[87] = 0.26973066f;
      sa[88] = -0.39131647f;
      sa[89] = -0.17096204f;
      sa[90] = -0.3288864f;
      sa[91] = 0.43023074f;
      sa[92] = -0.13803518f;
      sa[93] = 0.13002738f;
      sa[94] = -0.45632493f;
      sa[95] = 0.006484687f;
      sa[96] = -0.23893164f;
      sa[97] = -0.056927215f;
      sa[98] = -0.09847081f;
      sa[99] = -0.14473705f;
      sa[100] = -0.27641794f;
      sa[101] = -0.06808333f;
      sa[102] = 0.14137135f;
      sa[103] = -0.0054162745f;
      sa[104] = -0.13093661f;
      sa[105] = -0.17062096f;
      sa[106] = 0.37799338f;
      sa[107] = 0.29280207f;
      sa[108] = 0.14462997f;
      sa[109] = -0.12103656f;
      sa[110] = 0.08153011f;
      sa[111] = -0.35938853f;
      sa[112] = -0.2597178f;
      sa[113] = 0.0083626965f;
      sa[114] = 0.067489766f;
      sa[115] = -0.13436683f;
      sa[116] = 0.41933396f;
      sa[117] = 0.049649812f;
      sa[118] = -0.40713423f;
      sa[119] = -0.19987185f;
      sa[120] = -0.12607439f;
      sa[121] = 0.2761799f;
      sa[122] = -0.081156805f;
      sa[123] = 0.008975027f;
      sa[124] = -0.2172067f;
      sa[125] = 0.20699443f;
      sa[126] = -0.27165434f;
      sa[127] = 0.062721334f;
      sa[128] = -0.3432012f;
      sa[129] = 0.19079725f;
      sa[130] = 0.0532347f;
      sa[131] = 0.2976797f;
      sa[132] = 0.17330371f;
      sa[133] = 0.072347306f;
      sa[134] = 0.22829118f;
      sa[135] = -0.28248847f;
      sa[136] = 0.18296364f;
      sa[137] = -0.407487f;
      sa[138] = 0.012641452f;
      sa[139] = 0.2662822f;
      sa[140] = -0.15196398f;
      sa[141] = -0.058413196f;
      sa[142] = 0.22472325f;
      sa[143] = -0.3218002f;
      sa[144] = 0.2890139f;
      sa[145] = -0.14757438f;
      sa[146] = 0.014134749f;
      sa[147] = 0.030901583f;
      sa[148] = -0.31095502f;
      sa[149] = 0.22460718f;
      sa[150] = -0.15608087f;
      sa[151] = -0.50278884f;
      sa[152] = 0.5652179f;
      sa[153] = -0.32238755f;
      sa[154] = 0.43416584f;
      sa[155] = -0.4420316f;
      sa[156] = -0.39530843f;
      sa[157] = -0.23794043f;
      sa[158] = 0.037137866f;
      sa[159] = -0.08218886f;
      sa[160] = 0.3217825f;
      sa[161] = -0.31767207f;
      sa[162] = 0.5156433f;
      sa[163] = -0.3090885f;
      sa[164] = 0.25982526f;
      sa[165] = -0.14918706f;
      sa[166] = 0.2505161f;
      sa[167] = -0.44603235f;
      sa[168] = 0.18320316f;
      sa[169] = -0.44043502f;
      sa[170] = 0.25292295f;
      sa[171] = 0.2006564f;
      sa[172] = 0.35841653f;
      sa[173] = 0.31519103f;
      sa[174] = -0.06063197f;
      sa[175] = -0.109771505f;
      sa[176] = -0.0060190675f;
      sa[177] = 0.3342266f;
      sa[178] = -0.42033464f;
      sa[179] = -0.09559799f;
      sa[180] = -0.25336823f;
      sa[181] = -0.21521366f;
      sa[182] = 0.060887225f;
      sa[183] = 0.042207755f;
      sa[184] = 0.3973675f;
      sa[185] = 0.5254115f;
      sa[186] = -0.009617595f;
      sa[187] = -0.4882556f;
      sa[188] = 0.094518386f;
      sa[189] = -0.23157926f;
      sa[190] = -0.27072972f;
      sa[191] = -0.34984174f;
      sa[192] = -0.11325539f;
      sa[193] = 0.23764133f;
      sa[194] = -0.15034547f;
      sa[195] = -0.010469479f;
      sa[196] = 0.1533688f;
      sa[197] = -0.23457083f;
      sa[198] = 0.24325362f;
      sa[199] = 0.47772723f;
      sa[200] = 0.05907716f;
      sa[201] = 0.26570836f;
      sa[202] = 0.20134692f;
      sa[203] = -0.37369925f;
      sa[204] = 0.17017898f;
      sa[205] = 0.46838436f;
      sa[206] = 0.0037688322f;
      sa[207] = 0.23206022f;
      sa[208] = -0.052018255f;
      sa[209] = 0.2283477f;
      sa[210] = -0.081753254f;
      sa[211] = -0.3126598f;
      sa[212] = -0.27060592f;
      sa[213] = 0.20054181f;
      sa[214] = -0.3645475f;
      sa[215] = -0.0360258f;
      sa[216] = 0.0966821f;
      sa[217] = 0.5031614f;
      sa[218] = 0.044608887f;
      sa[219] = 0.20249645f;
      sa[220] = 0.13712426f;
      sa[221] = 0.043265793f;
      sa[222] = -0.36315808f;
      sa[223] = -0.23920146f;
      sa[224] = 0.2674296f;
      sa[225] = -0.07272083f;
      sa[226] = -0.20051597f;
      sa[227] = -0.031083997f;
      sa[228] = -0.24566764f;
      sa[229] = -0.23553623f;
      sa[230] = -0.3236743f;
      sa[231] = -0.30524778f;
      sa[232] = 0.34802082f;
      sa[233] = -0.19481166f;
      sa[234] = -0.26783884f;
      sa[235] = 0.065324746f;
      sa[236] = -0.4406611f;
      sa[237] = 0.45475468f;
      sa[238] = -0.04076134f;
      sa[239] = 0.042569965f;
      sa[240] = -0.27184293f;
      sa[241] = -0.4798667f;
      sa[242] = -0.2852268f;
      sa[243] = 0.48944977f;
      sa[244] = 0.0502915f;
      sa[245] = 0.23226307f;
      sa[246] = 0.3154934f;
      sa[247] = -0.5726403f;
      sa[248] = -0.093346834f;
      sa[249] = -0.147852f;
      sa[250] = 0.13323683f;
      sa[251] = 0.5773025f;
      sa[252] = 0.07617976f;
      sa[253] = -0.23405194f;
      sa[254] = 0.34503576f;
      sa[255] = 0.38128474f;
    }
  }
}
// Neuron weights connecting Rectifier and Softmax layer
class h2o_nn_16x16x6_ReLU_10_Weight_3 implements java.io.Serializable {
  public static final float[] VALUES = new float[96];
  static {
    h2o_nn_16x16x6_ReLU_10_Weight_3_0.fill(VALUES);
  }
  static final class h2o_nn_16x16x6_ReLU_10_Weight_3_0 implements java.io.Serializable {
    static final void fill(float[] sa) {
      sa[0] = -0.05491642f;
      sa[1] = -1.5810144f;
      sa[2] = -1.6068085f;
      sa[3] = 1.3620504f;
      sa[4] = 0.301148f;
      sa[5] = -0.1726591f;
      sa[6] = -1.6244388f;
      sa[7] = 1.3169136f;
      sa[8] = 1.7336376f;
      sa[9] = 0.025573654f;
      sa[10] = 1.5961893f;
      sa[11] = 1.2222587f;
      sa[12] = 1.7138959f;
      sa[13] = -0.8191661f;
      sa[14] = -2.0008857f;
      sa[15] = -0.72916263f;
      sa[16] = 0.71857816f;
      sa[17] = -0.78760093f;
      sa[18] = -1.4402717f;
      sa[19] = -1.0224801f;
      sa[20] = -1.9596983f;
      sa[21] = 0.2585191f;
      sa[22] = -1.9205986f;
      sa[23] = -0.7086651f;
      sa[24] = -0.48948684f;
      sa[25] = 1.9464743f;
      sa[26] = -0.29400024f;
      sa[27] = 1.2294625f;
      sa[28] = 1.225366f;
      sa[29] = -0.8834505f;
      sa[30] = 0.25307825f;
      sa[31] = 0.19110018f;
      sa[32] = 0.14076434f;
      sa[33] = 0.071689606f;
      sa[34] = -0.53493917f;
      sa[35] = 0.84615606f;
      sa[36] = 0.3005146f;
      sa[37] = -1.39445f;
      sa[38] = 0.5404498f;
      sa[39] = -0.58745706f;
      sa[40] = 0.29261664f;
      sa[41] = -0.7530646f;
      sa[42] = 0.5279558f;
      sa[43] = -0.4913246f;
      sa[44] = 0.8441393f;
      sa[45] = -2.5792487f;
      sa[46] = -2.052461f;
      sa[47] = 0.06331511f;
      sa[48] = 1.6940649f;
      sa[49] = -0.20151904f;
      sa[50] = -0.6650618f;
      sa[51] = 1.7820352f;
      sa[52] = -1.6507138f;
      sa[53] = 0.8647859f;
      sa[54] = 1.6623601f;
      sa[55] = 1.1243815f;
      sa[56] = -0.83560795f;
      sa[57] = -0.04826604f;
      sa[58] = 0.9231145f;
      sa[59] = 0.8637782f;
      sa[60] = -1.3960422f;
      sa[61] = 1.1067265f;
      sa[62] = -0.5117132f;
      sa[63] = -1.0212742f;
      sa[64] = 1.0289007f;
      sa[65] = -0.8477232f;
      sa[66] = -1.8601474f;
      sa[67] = -0.056287233f;
      sa[68] = 0.95073f;
      sa[69] = -1.3621941f;
      sa[70] = -1.5712076f;
      sa[71] = 0.023179993f;
      sa[72] = -1.0265195f;
      sa[73] = -1.2211497f;
      sa[74] = -1.171285f;
      sa[75] = 1.3926561f;
      sa[76] = 1.9667747f;
      sa[77] = -0.42690718f;
      sa[78] = -1.466212f;
      sa[79] = -0.45135993f;
      sa[80] = 0.53307873f;
      sa[81] = -1.7785292f;
      sa[82] = -0.35221326f;
      sa[83] = -1.4498885f;
      sa[84] = 1.5684761f;
      sa[85] = 1.1539304f;
      sa[86] = -1.9969093f;
      sa[87] = 1.0901128f;
      sa[88] = -1.6386523f;
      sa[89] = -1.1608812f;
      sa[90] = 0.20760587f;
      sa[91] = 0.0894325f;
      sa[92] = 1.2010427f;
      sa[93] = 1.8115412f;
      sa[94] = 1.5738782f;
      sa[95] = 0.6415532f;
    }
  }
}
// The class representing training column names
class NamesHolder_h2o_nn_16x16x6_ReLU_10 implements java.io.Serializable {
  public static final String[] VALUES = new String[13];
  static {
    NamesHolder_h2o_nn_16x16x6_ReLU_10_0.fill(VALUES);
  }
  static final class NamesHolder_h2o_nn_16x16x6_ReLU_10_0 implements java.io.Serializable {
    static final void fill(String[] sa) {
      sa[0] = "X5";
      sa[1] = "X12";
      sa[2] = "X15";
      sa[3] = "X17";
      sa[4] = "X18";
      sa[5] = "X19";
      sa[6] = "X20";
      sa[7] = "X21";
      sa[8] = "X23";
      sa[9] = "X27";
      sa[10] = "X28";
      sa[11] = "X34";
      sa[12] = "X35";
    }
  }
}
// The class representing column Label
class h2o_nn_16x16x6_ReLU_10_ColInfo_13 implements java.io.Serializable {
  public static final String[] VALUES = new String[6];
  static {
    h2o_nn_16x16x6_ReLU_10_ColInfo_13_0.fill(VALUES);
  }
  static final class h2o_nn_16x16x6_ReLU_10_ColInfo_13_0 implements java.io.Serializable {
    static final void fill(String[] sa) {
      sa[0] = "1";
      sa[1] = "2";
      sa[2] = "3";
      sa[3] = "4";
      sa[4] = "5";
      sa[5] = "6";
    }
  }
}


